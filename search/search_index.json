{"config":{"lang":["de"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Willkommen auf rwcloud.ch Wiki","text":"<p>Dieses Wiki beinhaltet eine Themen rund Themen wie Hosting und Betrieb von Homlab Servies wie Docker, Ansible und AI. In diesem Wiki dokumentiere ich mein Wissen \u00fcber verschiedene Tehmen. </p> <p>Es wird keine Garantie auf Korrektheit gegeben.</p>"},{"location":"ai/ollama/","title":"Ollama","text":"<p>Hier werden in Zukunft Themen zur lokal betriebenen AI/KI Ollama ver\u00f6ffentlicht.</p>"},{"location":"ansible/ansible-vault/","title":"Ansible-Vault","text":""},{"location":"ansible/ansible-vault/#vault-password-file","title":"Vault Password File","text":"<p>Das Passwordfile lege ich entsprechenden Unterverzeichnis des Verzeichnisses playbooks an. Variable \"my secret\" mit dem Passwort ersetzen. ACHTUNG: Des Verschl\u00fcsselungspasswort im Passwort-Manager ablegen. Da dieses File beim wechseln des Ausf\u00fchrungsservers/Containers manuell erstellt werden muss. Ansonsten k\u00f6nnen die Ansilbe Vault Variablen nicht mehr entschl\u00fcsselt/verschl\u00fcsselt werden.</p> Passwortfile erstellen und sch\u00fctzen<pre><code>echo \"my secret\" &gt; .vault_pass\n\n-- Datei noch sch\u00fctzen\nchmod 600 .vault_pass\n</code></pre>"},{"location":"ansible/ansible-vault/#eine-variable-verschlusseln","title":"Eine Variable verschl\u00fcsseln","text":"<p>Um eine Variable mit Ansible-Vault zu verschl\u00fcsseln kann folgender Befehl verwendet werden:</p> <p>Beispiel Passwort verschl\u00fcsseln<pre><code>ansible-vault encrypt_string --vault-id [deine-vaultid]@.vault_pass --encrypt-vault-id [deine-vaultid] 'dein passwort' --name 'ansibe-variabelen-name'\n</code></pre> Damit wird f\u00fcr die die definierte Vault-Id mit der Password-Datei .vault_pass das eingegbene Passwort verschl\u00fcsselt.</p>"},{"location":"ansible/ansible/","title":"Stuktur und Aufbau des Repos","text":"<pre><code>ansible-devcontainer/\n\u251c\u2500\u2500 .devcontainer/ # Dev container configuration (e.g., Dockerfile)\n\u251c\u2500\u2500 .secrets/ # Secrets management (e.g., encrypted files)\n\u251c\u2500\u2500 inventory/ # Inventory definition\n\u2502   \u251c\u2500\u2500 hosts.yml # Main inventory file\n\u2502   \u2514\u2500\u2500 groups/\n\u2502       \u2514\u2500\u2500 group1.yml # Group-specific inventory definitions\n\u2502       \u2514\u2500\u2500 group2.yml # Another group-specific inventory definition\n\u2502   \u2514\u2500\u2500 host_vars/\n\u2502       \u251c\u2500\u2500 host1.yml\n\u2502       \u2514\u2500\u2500 host2.yml # Host-specific variable files\n\u2502\n\u251c\u2500\u2500 playbooks/ # Playbook directory (main entry points for your infrastructure)\n\u2502   \u2514\u2500\u2500 environment-1/ # Environment-specific playbooks\n\u2502       \u251c\u2500\u2500 deploy.yml\n\u2502       \u2514\u2500\u2500 config.yml\n\u2502   \u2514\u2500\u2500 environment-2/ # Another environment-specific playbook set\n\u2502       \u251c\u2500\u2500 deploy.yml\n\u2502       \u2514\u2500\u2500 config.yml\n\u2502\n\u251c\u2500\u2500 roles/ # Roles directory ( reusable pieces of Ansible code)\n\u2502   \u251c\u2500\u2500 role1/\n\u2502   \u2502   \u251c\u2500\u2500 tasks/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 main.yml\n\u2502   \u2502   \u251c\u2500\u2500 defaults/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 main.yml\n\u2502   \u2502   \u2514\u2500\u2500 files/\n\u2502   \u2502       \u2514\u2500\u2500 file\n\u2502   \u2514\u2500\u2500 role2/\n\u2502       \u251c\u2500\u2500 tasks/\n\u2502       \u2502   \u2514\u2500\u2500 main.yml\n\u2502       \u251c\u2500\u2500 defaults/\n\u2502       \u2502   \u2514\u2500\u2500 main.yml\n\u2502       \u2514\u2500\u2500 files/\n\u2502           \u2514\u2500\u2500 file\n\u2502\n\u251c\u2500\u2500 readme.md # Project documentation and usage information\n</code></pre>"},{"location":"ansible/ansible/#ansible-ausfuhren","title":"Ansible ausf\u00fchren","text":"<p>Erkl\u00e4rung des n\u00e4chsten Befehlts:</p> <p>-i: Pfad zum Hosts-File --vault-password-file: Pfad und Name des Password-Files f\u00fcr die Ansible Vault. --limit: Nur dieser Host wird ausgef\u00fchrt.</p> Playbook starten<pre><code>ansible-playbook -i ../inventory/hosts.yml --vault-password-file ../rwcloud.vault_pass  test_connection.yml --limit testbox\n</code></pre>"},{"location":"ansible/devcontainer/","title":"Ansible in einem Devcontainer betreiben","text":"<p>Um Ansible in einem Devcontainer zu betreiben sind folgene Schritte notwendig:</p> <p>Ansible lint funktioniert nicht - Work in progress</p> <p>Im devcontainer ist Ansible lint nicht funktionst\u00fcchtig.</p>"},{"location":"ansible/devcontainer/#zielsetzung","title":"Zielsetzung:","text":"<p>Die Entwicklung und der Betrieb soll vom Arbeits-PC/Notebook m\u00f6glichst separiert werden. Die Entwicklung und Ausf\u00fcrhung der Ansible Befehle wird in VS-Code geschehen. Daher bietet es sich an, Ansible in einem Devcontainer zu betreiben. Damit kann die Abstraktion zur Host-Maschiene sichergestellt werden. Zudem kann auf jedem Rechner auf welchem Docker und VS-Code installiert ist, der Devcontainer betrieben betrieben werden.</p> <p>Im Devcontainer sollen auch die SSH Keys vorhanden sein um eine SSH Verbindung zu den Remotehosts aufzubauen. Diese werden mit dem decontainer.json File in den Container gemountet.</p> <p>Zusatzfunktion im Devcontainer</p> <p>Im Devcontainer ist zus\u00e4tzlich noch oh-my-zsh installiert. Das Terminal soll ja schliesslich auch eine \"gute Falle\" machen. </p>"},{"location":"ansible/devcontainer/#devcontainer-erstellen-und-starten","title":"Devcontainer erstellen und starten","text":""},{"location":"ansible/devcontainer/#1-projektverzeichnis-erstellen-mit","title":"1. Projektverzeichnis erstellen mit","text":"Shell<pre><code>  mkdir my-ansible-project \n</code></pre>"},{"location":"ansible/devcontainer/#2-dockerfile-erstellen-beispiel-version-muss-ggf-angepasst-werden","title":"2. Dockerfile erstellen. Beispiel (Version muss ggf. angepasst werden)","text":"<p>Ordner \".devcontainer\" erstellen und im Ordner die Datei \"Dockerfile\" anlegen.</p> Dockerfile<pre><code>FROM python:3.12-slim\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    git \\\n    zsh \\\n    wget \\\n    curl \\\n    sudo \\\n    ansible-lint \\\n    &amp;&amp; apt-get clean\n\n# Create ansible user with zsh as default shell\nRUN useradd -ms /bin/zsh ansible\n\n# Switch to ansible user\nUSER ansible\nWORKDIR /home/ansible\n\n# Install Oh-My-Zsh for ansible user\nRUN sh -c \"$(wget https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\"\n\n# Install zsh-autosuggestions and powerlevel9k\n#RUN apt-get install -y zsh-autosuggestions powerlevel9k\n\n# Switch back to root to copy .zshrc and install Ansible\nUSER root\n\n# Copy a custom .zshrc if you have one\nCOPY .zshrc /home/ansible/.zshrc\n\n# Change ownership of the home directory\nRUN chown -R ansible:ansible /home/ansible\n\n# Install Ansible with matching versions\n# RUN pip install ansible==2.14.1 &amp;&amp; apt-get install -y ansible=2.14.1\n\n# Set the working directory\nWORKDIR /workspace\n\n# Copy the current directory contents into the container at /workspace\nCOPY . /workspace\n\n# Change default shell to zsh for the container user\nUSER ansible\nSHELL [\"/bin/zsh\", \"-c\"]\n</code></pre>"},{"location":"ansible/devcontainer/#3-erstellen-sie-eine-devcontainerjson-datei-um-den-devcontainer-zu-konfigurieren","title":"3.  Erstellen Sie eine devcontainer.json Datei, um den Devcontainer zu konfigurieren","text":"<p>Ordner \".devcontainer\" erstellen und im Ordner die Datei devcontainer.json anlegen.</p> devcontainer.json<pre><code>{\n    \"name\": \"Ansible Devcontainer\",\n    \"build\": {\n        \"dockerfile\": \"Dockerfile\",\n        \"context\": \".\"\n    },\n    \"workspaceFolder\": \"/workspace\",\n    \"extensions\": [\n        \"ms-azuretools.vscode-docker\",\n        \"redhat.ansible\"\n    ],\n    \"settings\": {\n        \"terminal.integrated.shell.linux\": \"/bin/zsh\"\n    },\n    \"mounts\": [\n        \"source=/pfad/zu/meinem/git-repo/ansible-devcontainer,target=/workspace,type=bind\",\n        \"source=/pfad/zu/meinem/git-repo/ansible-devcontainer/.secrets,target=/home/ansible/.secrets,type=bind\" /* ACHTUNG: .secrets ordner muss ausserhalb des .devcontainer Ordner liegen */\n    ],\n    \"remoteUser\": \"ansible\",\n    \"remoteEnv\": {\n        \"ANSIBLE_VAULT_PASSWORD_FILE\": \"/home/ansible/.secrets/vie.vault_pass\",\n        \"ANSIBLE_PRIVATE_KEY_FILE\": \"/home/ansible/.secrets/ansible\"\n    }\n}\n</code></pre>"},{"location":"ansible/devcontainer/#devcontainer-starten","title":"Devcontainer starten","text":"<p>Den Ordner des Repos in VSCode \u00f6ffnen. Wenn der Dialog zum statarten des Devcontainers nicht angezeigt wird kann man mit dem Taskenkombination SHIFT+CMD+P ausw\u00e4hlen und \"Remote-Containers: Start Remote Container\" ausw\u00e4hlen.</p>"},{"location":"apps/bind9/","title":"BIND9","text":"<p>BIND9 (Berkeley Internet Name Domain Version 9) ist ein Open-Source-[[DNS]] (Domain Name System) Softwaresystem. Es ist die am weitesten verbreitete DNS-Server-Software im Internet und wird vom Internet Systems Consortium (ISC) gepflegt. BIND9 bietet eine robuste und skalierbare Plattform zur Aufl\u00f6sung von Domainnamen in IP-Adressen und umgekehrt und unterst\u00fctzt erweiterte DNS-Funktionen wie [[DNSSEC]] (DNS Security Extensions), dynamische Updates und inkrementelle Zonentransfers. BIND9 l\u00e4uft auf einer Vielzahl von Betriebssystemen, einschlie\u00dflich [[Linux]], [[Unix]] und [[Windows]], und ist hochgradig konfigurierbar und erweiterbar durch die Verwendung von Plugins und Modulen.</p> <p>Project Homepage: https://www.isc.org/bind/</p>"},{"location":"apps/bind9/#installation","title":"Installation","text":"<p>ISC stellt ausf\u00fchrbare Dateien f\u00fcr Windows und Pakete f\u00fcr Ubuntu, CentOS, Fedora und Debian bereit - BIND 9 ESV, Debian - BIND 9 Stable, Debian - BIND 9 Development Version. Die meisten Betriebssysteme bieten auch BIND 9-Pakete f\u00fcr ihre Benutzer an. Diese k\u00f6nnen mit einer anderen Standardkonfiguration als der Standard-BIND 9-Distribution erstellt worden sein, und einige von ihnen f\u00fcgen eine eigene Versionsnummer hinzu, die nicht genau der BIND 9-Version entspricht.</p>"},{"location":"apps/bind9/#ubuntu-linux","title":"Ubuntu Linux","text":"<p>BIND9 ist im Main-Repository verf\u00fcgbar. Es muss kein zus\u00e4tzliches Repository f\u00fcr BIND9 aktiviert werden.</p> <pre><code>sudo apt install bind9\n</code></pre>"},{"location":"apps/bind9/#ubuntu-docker","title":"Ubuntu Docker","text":"<p>Als Teil der Long Term Supported OCI Images, bietet Canonical Bind9 als geh\u00e4rtetes und gewartetes Docker-Image an.</p> <pre><code>docker run -d --name bind9-container -e TZ=UTC -p 30053:53 ubuntu/bind9:9.18-22.04_beta\n</code></pre>"},{"location":"apps/bind9/#configuration","title":"Configuration","text":"<p>BIND 9 verwendet eine einzige Konfigurationsdatei namens <code>named.conf</code>, die sich typischerweise entweder in <code>/etc/bind</code>, <code>/etc/namedb</code> oder <code>/usr/local/etc/namedb</code> befindet.</p> <p>Die named.conf besteht aus <code>logging-</code> und <code>options</code>-Bl\u00f6cken sowie <code>category-</code>, <code>channel-</code>, <code>directory-</code>, <code>file-</code> und <code>severity-</code>Anweisungen.</p>"},{"location":"apps/bind9/#named-config","title":"Named Config","text":"<pre><code>options {\n    ...\n};\n\nzone \"domain.tld\" {\n    type primary;\n    file \"domain.tld\";\n};\n</code></pre>"},{"location":"apps/bind9/#zone-file","title":"Zone File","text":"<p>Je nach Funktionalit\u00e4t des Systems ist eine oder mehrere Zonendateien erforderlich.</p> <pre><code>; base zone file for domain.tld\n$TTL 2d    ; default TTL for zone\n\n$ORIGIN domain.tld. ; base domain-name\n\n; Start of Authority RR defining the key characteristics of the zone (domain)\n@         IN      SOA   ns1.domain.tld. hostmaster.domain.tld. (\n                                2022121200 ; serial number\n                                12h        ; refresh\n                                15m        ; update retry\n                                3w         ; expiry\n                                2h         ; minimum\n                                )\n\n; name server RR for the domain\n           IN      NS      ns1.domain.tld.\n\n; mail server RRs for the zone (domain)\n        3w IN      MX  10  mail.domain.tld.\n\n; domain hosts includes NS and MX records defined above\n; plus any others required\n; for instance a user query for the A RR of joe.domain.tld will\n; return the IPv4 address 192.168.254.6 from this zone file\nns1        IN      A       192.168.254.2\nmail       IN      A       192.168.254.4\njoe        IN      A       192.168.254.6\nwww        IN      A       192.168.254.7\n</code></pre>"},{"location":"apps/bind9/#soa-start-of-authority","title":"SOA (Start of Authority)","text":"<p>Ein Start of Authority-Eintrag ist eine Art Ressourceneintrag im Domain Name System (DNS) der administrative Informationen \u00fcber die Zone enth\u00e4lt, insbesondere in Bezug auf Zonentransfers. Das SOA-Eintragsformat ist in RFC 1035 spezifiziert.</p> <pre><code>@         IN      SOA   ns1.domain.tld. hostmaster.domain.tld. (\n                                2022121200 ; serial number\n                                12h        ; refresh\n                                15m        ; update retry\n                                3w         ; expiry\n                                2h         ; minimum\n                                )\n</code></pre>"},{"location":"apps/bind9/#forwarders-weiterleitungen","title":"Forwarders (Weiterleitungen)","text":"<p>DNS-Weiterleitungen sind Server, die DNS-Abfragen im Namen eines anderen DNS-Servers aufl\u00f6sen.</p> <p>Um bind9 als weiterleitenden DNS-Server zu konfigurieren, muss eine <code>forwarders-</code>Klausel innerhalb des <code>options-</code>Blocks hinzugef\u00fcgt werden. Die <code>forwarders-</code>Klausel gibt eine Liste von IP-Adressen anderer DNS-Server an, an die bind9 Abfragen weiterleiten wird.</p> <pre><code>options {\n    // ... other options ...\n    forwarders {\n        8.8.8.8; // Google Public DNS\n        1.1.1.1; // Cloudflare DNS\n    };\n};\n</code></pre>"},{"location":"apps/bind9/#access-control-zugriffskontrolle","title":"Access Control (Zugriffskontrolle)","text":"<p>Um Berechtigungen in BIND9 zu konfigurieren, k\u00f6nnen Sie die \u201cacl\u201d-Anweisung verwenden, um Zugriffskontrolllisten zu definieren, und dann die Anweisungen \u201callow-query\u201d und \u201callow-transfer\u201d verwenden, um anzugeben, welche Hosts oder Netzwerke Abfragen oder Zonen \u00fcbertragen d\u00fcrfen.</p> <pre><code>acl \"trusted\" {\n    192.168.1.0/24;\n    localhost;\n};\n\noptions {\n    // ...\n    allow-query { any; };\n    allow-transfer { \"trusted\"; };\n    // ...\n};\n\nzone \"example.com\" {\n    // ...\n    allow-query { \"trusted\"; };\n    // ...\n};\n</code></pre> <p>In diesem Beispiel definieren wir eine ACL namens \u201ctrusted\u201d, die das Netzwerk 192.168.1.0/24 und den lokalen Host umfasst. Wir geben dann an, dass Hosts in dieser ACL Zonen \u00fcbertragen d\u00fcrfen und dass jeder Host Abfragen durchf\u00fchren darf.</p> <p>F\u00fcr die Zone \u201cexample.com\u201d geben wir an, dass nur Hosts in der ACL \u201ctrusted\u201d Abfragen durchf\u00fchren d\u00fcrfen.</p> <p>Sie k\u00f6nnen auch andere ACL-Funktionen verwenden, wie \u201callow-recursion\u201d und \u201callow-update\u201d, um den Zugriff auf Ihren DNS-Server weiter zu kontrollieren.</p>"},{"location":"apps/bind9/#dynamic-updates","title":"Dynamic Updates","text":"<p>Dynamische Updates in BIND erm\u00f6glichen die \u00c4nderung von DNS-Eintr\u00e4gen in Echtzeit, ohne Zonendateien manuell bearbeiten zu m\u00fcssen.</p>"},{"location":"apps/bind9/#secure-dns-updates-with-tsig-key","title":"Secure DNS updates with TSIG Key","text":"<p>Dynamische Updates in BIND erm\u00f6glichen die \u00c4nderung von DNS-Eintr\u00e4gen in Echtzeit, ohne Zonendateien manuell bearbeiten zu m\u00fcssen.</p> <p>Um einen TSIG-Schl\u00fcssel f\u00fcr die Verwendung mit dynamischen Updates zu erstellen, kann der Befehl <code>tsig-keygen</code> verwendet werden.</p> <pre><code>tsig-keygen -a hmac-sha256\n</code></pre> <p>Um den TSIG-Schl\u00fcssel zur Zonenkonfiguration hinzuzuf\u00fcgen, muss die \u201ckey\u201d-Anweisung zur \u201callow-update\u201d-Anweisung in der named.conf-Datei hinzugef\u00fcgt werden. Zum Beispiel:</p> <pre><code>zone \"example.com\" {\n    type master;\n    file \"example.com.zone\";\n    allow-update { key \"tsig-key\"; };\n};\n</code></pre> <p>In diesem Beispiel verwendet die \u201callow-update\u201d-Anweisung nun den TSIG-Schl\u00fcssel, um Updates f\u00fcr die Zone \u201cexample.com\u201d zuzulassen.</p>"},{"location":"apps/grafana/","title":"Grafana","text":"<p>Grafana ist eine Open-Source-Analyse- und \u00dcberwachungsplattform, die f\u00fcr die Erstellung von Dashboards und die Visualisierung von Metriken aus verschiedenen Datenquellen verwendet wird. Es ist besonders n\u00fctzlich f\u00fcr die \u00dcberwachung von Anwendungen, Servern, Netzwerken und anderen IT-Infrastrukturen.</p>"},{"location":"apps/grafana/#funktionen","title":"Funktionen","text":"<ul> <li>Dashboards: Grafana erm\u00f6glicht die Erstellung interaktiver und anpassbarer Dashboards.</li> <li>Datenquellen: Unterst\u00fctzt eine Vielzahl von Datenquellen wie Prometheus, InfluxDB, Graphite, Elasticsearch, MySQL, PostgreSQL und viele mehr.</li> <li>Benachrichtigungen: Integration von Benachrichtigungen bei bestimmten Ereignissen oder Schwellenwerten.</li> <li>Benutzerverwaltung: Verwaltung von Benutzerrechten und Teams, um den Zugriff auf Dashboards und Datenquellen zu steuern.</li> <li>Plug-in-Architektur: Erweiterbar durch eine Vielzahl von Plug-ins f\u00fcr neue Datenquellen, Visualisierungen und Anwendungen.</li> </ul>"},{"location":"apps/grafana/#installation","title":"Installation","text":""},{"location":"apps/grafana/#docker","title":"Docker","text":"<p>Um Grafana mit Docker zu installieren, f\u00fchren Sie den folgenden Befehl aus:</p> <pre><code>docker run -d -p 3000:3000 --name=grafana grafana/grafana\n</code></pre>"},{"location":"apps/grafana/#verwendung","title":"Verwendung","text":"<p>Nach der Installation und dem Starten des Grafana-Dienstes k\u00f6nnen Sie \u00fcber einen Webbrowser auf das Dashboard zugreifen: <pre><code>http://localhost:3000\n</code></pre></p> <p>Der Standardbenutzername und das Standardpasswort sind admin. Nach dem ersten Login werden Sie aufgefordert, das Passwort zu \u00e4ndern.</p>"},{"location":"apps/grafana/#hinzufugen-einer-datenquelle","title":"Hinzuf\u00fcgen einer Datenquelle","text":"<p>Um eine neue Datenquelle hinzuzuf\u00fcgen, gehen Sie zu Configuration -&gt; Data Sources -&gt; Add data source und w\u00e4hlen Sie den gew\u00fcnschten Datentyp aus.</p>"},{"location":"apps/grafana/#erstellung-eines-dashboards","title":"Erstellung eines Dashboards","text":"<pre><code>1.  Gehen Sie zu Create -&gt; Dashboard.\n2.  F\u00fcgen Sie ein neues Panel hinzu.\n3.  W\u00e4hlen Sie die Datenquelle und die Metriken aus, die Sie visualisieren m\u00f6chten.\n4.  Konfigurieren Sie die Visualisierungsoptionen nach Ihren W\u00fcnschen.\n</code></pre>"},{"location":"apps/grafana/#dokumentation-und-unterstutzung","title":"Dokumentation und Unterst\u00fctzung","text":"<p>F\u00fcr weitere Informationen und detaillierte Anleitungen besuchen Sie die offizielle Dokumentation:</p> <p>Grafana Dokumentation</p>"},{"location":"apps/prometheus/","title":"Prometheus","text":"<p>Prometheus ist ein Open-Source-System zur \u00dcberwachung und Alarmierung, das urspr\u00fcnglich von SoundCloud entwickelt wurde. Es wurde entwickelt, um Metriken aus verschiedenen Zielen effizient zu erfassen und zu speichern und erm\u00f6glicht das Erstellen umfangreicher Dashboards und Benachrichtigungen basierend auf diesen Metriken.</p>"},{"location":"apps/prometheus/#funktionen","title":"Funktionen","text":"<ul> <li>Multi-dimensionales Datenmodell: Metriken werden anhand von Schl\u00fcssel-Wert-Paaren (Labels) identifiziert.</li> <li>Flexible Abfragesprache: PromQL (Prometheus Query Language) erm\u00f6glicht komplexe Abfragen und Analysen.</li> <li>Eigenst\u00e4ndige Zeitreihendatenbank: Speichert alle gesammelten Daten.</li> <li>Pushing und Pulling von Metriken: Unterst\u00fctzt sowohl das Pulling von Metriken \u00fcber HTTP als auch das Pushing von Metriken \u00fcber das Pushgateway.</li> <li>Service Discovery: Automatische Erkennung von Diensten zur \u00dcberwachung.</li> <li>Alertmanager: Verwaltung und Versenden von Benachrichtigungen basierend auf konfigurierten Regeln.</li> </ul>"},{"location":"apps/prometheus/#installation","title":"Installation","text":""},{"location":"apps/prometheus/#docker","title":"Docker","text":"<p>Um Prometheus mit Docker zu installieren, f\u00fchren Sie den folgenden Befehl aus:</p> <pre><code>docker run -d -p 9090:9090 --name=prometheus prom/prometheus\n</code></pre>"},{"location":"apps/prometheus/#konfiguration","title":"Konfiguration","text":"<p>Die Standardkonfigurationsdatei f\u00fcr Prometheus ist <code>prometheus.yml</code>, die sich typischerweise in <code>/etc/prometheus</code> befindet. Diese Datei definiert, welche Ziele \u00fcberwacht werden sollen und wie lange Daten aufbewahrt werden.</p>"},{"location":"apps/prometheus/#basiskonfiguration","title":"Basiskonfiguration","text":"<pre><code>global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: ['localhost:9090']\n</code></pre>"},{"location":"apps/prometheus/#verwendung","title":"Verwendung","text":""},{"location":"apps/prometheus/#zugriff-auf-da-dashboard","title":"Zugriff auf da Dashboard","text":"<p>Nach der Installation und dem Starten des Prometheus-Dienstes k\u00f6nnen Sie \u00fcber einen Webbrowser auf das Dashboard zugreifen: <pre><code>http://localhost:9090\n</code></pre></p>"},{"location":"apps/prometheus/#dokumentation","title":"Dokumentation","text":"<p>F\u00fcr weitere Informationen und detaillierte Anleitungen besuchen Sie die offizielle Dokumentation:</p> <p>Prometheus Documentation</p>"},{"location":"databases/mariadb/","title":"MariaDB Cheat-Sheet","text":"<p>MariaDB Server is one of the most popular open source relational databases. It\u2019s made by the original developers of MySQL and guaranteed to stay open source. It is part of most cloud offerings and the default in most Linux distributions.</p> <p>It is built upon the values of performance, stability, and openness, and MariaDB Foundation ensures contributions will be accepted on technical merit. Recent new functionality includes advanced clustering with Galera Cluster 4, compatibility features with Oracle Database and Temporal Data Tables, allowing one to query the data as it stood at any point in the past.</p> <p>Project Homepage: MariaDB Documentation: MariaDB Docs</p>"},{"location":"databases/mariadb/#installation","title":"Installation","text":""},{"location":"databases/mariadb/#install-mariadb-on-debianubuntumintzorinforks","title":"Install MariaDB on Debian/Ubuntu/Mint/Zorin/forks","text":"<pre><code>sudo apt update\nsudo apt install -y mariadb-server mycli --install-recommends\nsudo mysql_secure_installation\n</code></pre>"},{"location":"databases/mariadb/#install-mariadb-on-rhelfedoracentosalmarocky","title":"Install MariaDB on RHEL/Fedora/CentOS/Alma/Rocky","text":"<pre><code>sudo dnf update\nsudo dnf install -y mariadb-server mycli\nsudo mysql_secure_installation\n</code></pre>"},{"location":"databases/mariadb/#install-mariadb-on-archmanjaroarcoforks","title":"Install MariaDB on Arch/Manjaro/Arco/forks","text":"<pre><code>sudo pacman -Syyu\nsudo pacman -S mariadb-server mycli --noconfirm\nsudo mysql_secure_installation\n</code></pre>"},{"location":"databases/mariadb/#deploy-mariadb-in-docker","title":"Deploy MariaDB in Docker","text":"<ul> <li>https://hub.docker.com/_/mariadb</li> <li>https://docs.linuxserver.io/images/docker-mariadb/</li> </ul>"},{"location":"databases/mariadb/#deploy-mariadb-in-kubernetes","title":"Deploy MariaDB in Kubernetes","text":"<ul> <li>https://mariadb.org/start-mariadb-in-k8s/</li> <li>https://kubedb.com/kubernetes/databases/run-and-manage-mariadb-on-kubernetes/</li> </ul>"},{"location":"databases/mariadb/#access-database-from-outside","title":"Access Database from outside","text":"<p>Open <code>/etc/mysql/mariadb.conf.d/50-server.cnf</code> and change the line containing <code>bind-address</code> to <code>bind-address = 0.0.0.0</code>.</p>"},{"location":"databases/mariadb/#create-administrative-user","title":"Create Administrative User","text":"<p>Access the MySQL command line by entering <code>mysql -u root -p</code> in the shell followed by the Database <code>root</code> password.</p> <p>Create a new user <code>newuser</code> for the host <code>localhost</code> with a new <code>password</code>:</p> <pre><code>CREATE USER 'newuser'@'localhost' IDENTIFIED BY 'password';\n</code></pre> <p>Grant all permissions to the new user</p> <pre><code>GRANT ALL PRIVILEGES ON * . * TO 'newuser'@'localhost';\n</code></pre> <p>Update permissions</p> <pre><code>FLUSH PRIVILEGES\n</code></pre>"},{"location":"databases/mysql/","title":"MySQL Community Edition (CE) Cheat-Sheet","text":"<p>MySQL Community Edition is the freely downloadable version of the world's most popular open source database.</p> <p>Project Homepage: MySQL Community Edition Documentation: MySQL Docs</p> <p>Editor's note: The MariaDB Project was forked from MySQL when Sun Microsystems' intellectual property was acquired by Oracle.  MariaDB still shares enormous inter-compatibility with MySQL functions and software interoperability, and performance at most scales is arguably indiscernible from MySQL CE.  In this writers' opinion it is not beneficial in most cases to favor Oracle's monetized option over the GPL's MariaDB alternative.</p>"},{"location":"databases/mysql/#installation","title":"Installation","text":""},{"location":"databases/mysql/#install-mysql-on-debianubuntumintzorindeb-forks","title":"Install MySQL on Debian/Ubuntu/Mint/Zorin/Deb forks","text":"<p>[!warning] Common Debian repositories don't populate MySQL CE and require a vendor-provided repository available here.  The repo file in this example is current as of 2024-01-20.</p> <pre><code>sudo apt update\nsudo apt install -y lsb-release gnupg\nwget https://dev.mysql.com/get/mysql-apt-config_0.8.29-1_all.deb\nsudo dpkg -i mysql-apt-config_0.8.29-1_all.deb\nsudo mkdir /var/lib/mysql\nsudo apt update\nsudo apt install -y mysql-community-server mysql-common mycli --install-recommends\nsudo mysql_secure_installation\n</code></pre>"},{"location":"databases/mysql/#install-mysql-on-rhelfedoracentosalmarocky","title":"Install MySQL on RHEL/Fedora/CentOS/Alma/Rocky","text":"<pre><code>sudo dnf update\nsudo dnf install -y mysql-server mysql-common mycli\nsudo mysql_secure_installation\n</code></pre>"},{"location":"databases/mysql/#install-mysql-on-archmanjaroarco-arch-forks","title":"Install MySQL on Arch/Manjaro/Arco/ Arch forks","text":"<p>[!warning] Common Arch repositories don't populate MySQL CE and the vendor doesn't provide one.  The packages are available in the AUR but this is *not recommended* for a production environment!!</p>"},{"location":"databases/mysql/#enable-the-aur-if-not-already-available","title":"Enable the AUR (if not already available)","text":"<p>[!notice] This must be done by a non-root user! <pre><code>git clone https://aur.archlinux.org/yay.git\ncd yay\nmakepkg -si\n</code></pre></p>"},{"location":"databases/mysql/#proceed-with-installation-from-the-aur","title":"Proceed with installation from the AUR","text":"<pre><code>yay pacman -Syyu\nyay -S mysql mysql-utilities mycli --noconfirm\nsudo mysql_secure_installation\n</code></pre>"},{"location":"databases/mysql/#deploy-mysql-in-docker","title":"Deploy MySQL in Docker","text":"<ul> <li>https://hub.docker.com/_/mysql/</li> <li>https://dev.mysql.com/doc/mysql-installation-excerpt/8.0/en/docker-mysql-getting-started.html</li> </ul>"},{"location":"databases/mysql/#deploy-mysql-in-kubernetes","title":"Deploy MySQL in Kubernetes","text":"<ul> <li>https://dev.mysql.com/doc/mysql-operator/en/</li> <li>https://kubernetes.io/docs/tasks/run-application/run-single-instance-stateful-application/</li> </ul>"},{"location":"databases/mysql/#create-administrative-user","title":"Create Administrative User","text":"<p>Access the MySQL command line by entering <code>mysql -u root -p</code> in the shell followed by the Database <code>root</code> password.</p> <p>Create a new user <code>newuser</code> for the host <code>localhost</code> with a new <code>password</code>:</p> <pre><code>CREATE USER 'newuser'@'localhost' IDENTIFIED BY 'password';\n</code></pre> <p>Grant all permissions to the new user</p> <pre><code>GRANT ALL PRIVILEGES ON * . * TO 'newuser'@'localhost';\n</code></pre> <p>Update permissions</p> <pre><code>FLUSH PRIVILEGES\n</code></pre>"},{"location":"databases/postgres/","title":"PostgreSQL Cheat-Sheet","text":"<p>PostgreSQL or also known as Postgres, is a free and open-source relational database management system. PostgreSQL features transactions with Atomicity, Consistency, Isolation, Durability (ACID) properties automatically updatable views, materialized views, triggers, foreign keys, and stored procedures. It is designed to handle a range of workloads, from single machines to data warehouses or web services with many concurrent users.</p>"},{"location":"databases/postgres/#installation","title":"Installation","text":""},{"location":"databases/postgres/#install-postgresql-on-debianubuntumintzorinforks","title":"Install PostgreSQL on Debian/Ubuntu/Mint/Zorin/forks","text":"<pre><code>sudo apt update\nsudo apt install -y postgresql postgresql-contrib postgresql-client\nsudo systemctl status postgresql.service\n</code></pre>"},{"location":"databases/postgres/#install-postgresql-on-rhelfedoracentosalmarocky","title":"Install PostgreSQL on RHEL/Fedora/CentOS/Alma/Rocky","text":"<pre><code>sudo dnf update\nsudo dnf install -y postgresql-server\n</code></pre>"},{"location":"databases/postgres/#install-postgresql-on-archmanjaroarcoforks","title":"Install PostgreSQL on Arch/Manjaro/Arco/forks","text":"<pre><code>sudo pacman -Syyu\nsudo pacman -S postgresql --noconfirm\n</code></pre>"},{"location":"databases/postgres/#deploy-postgresql-in-docker","title":"Deploy PostgreSQL in Docker","text":"<ul> <li>https://hub.docker.com/_/postgres/</li> <li>https://github.com/postgres/postgres</li> </ul>"},{"location":"databases/postgres/#deploy-postgresql-on-kubernetes-with-zalando-postgres-operator","title":"Deploy PostgreSQL on Kubernetes with Zalando Postgres Operator","text":"<p>Postgres is probably the database which is most common on Cloud platforms and also, running on Kubernetes environments. There are several so called \"Kubernetes Operators\" which handle the deployment of Postgres clusters for you. One of it is the Postgres Operator by Zalando.</p> <p>You can find some tutorials regarding deployment of the operator and how to work with it, in the link list below:</p> <ul> <li>Deploy Zalando Postgres Operator on your Kubernetes cluster</li> <li>Configure Zalando Postgres Operator Backup with WAL-G</li> <li>Configure Zalando Postgres Operator Restore with WAL-G</li> </ul>"},{"location":"databases/postgres/#connecting-to-postgres","title":"Connecting to Postgres","text":""},{"location":"databases/postgres/#connect-to-local-postgres-instance","title":"Connect to local Postgres instance","text":"<p>A local connection (from the database server) can be done by the following command:</p> <pre><code>sudo -u postgres psql\n</code></pre>"},{"location":"databases/postgres/#connect-to-remote-postgres-instance","title":"Connect to remote Postgres instance","text":"<p>Note, that you first have to install the <code>postgresql-client</code> package, (<code>postgresql</code> via Homebrew on macOS) on the client machine. A connection from a remote host can be done by the following command:</p> <pre><code>psql -h {pg_host} -U {username} -d {database} -p {port}\n</code></pre>"},{"location":"databases/postgres/#set-password-for-postgres-database-user","title":"Set password for postgres database user","text":"<p>The password for the <code>postgres</code> database user can be set the the quickcommand <code>\\password</code> or by <code>alter user postgres password 'Supersecret'</code>. A connection using the <code>postgres</code> user is still not possible from the \"outside\" hence to the default settings in the <code>pg_hba.conf</code>.</p>"},{"location":"databases/postgres/#update-pg_hbaconf-to-allow-postgres-user-connections-with-password","title":"Update pg_hba.conf to allow postgres user connections with password","text":"<p>In order to allow connections of the <code>postgres</code> database user not using OS user authentication, you have to update the <code>pg_hba.conf</code> which can be found under <code>/etc/postgresql/12/main/pg_hba.conf</code>.</p> <pre><code>sudo vi /etc/postgresql/12/main/pg_hba.conf\n\n...\nlocal   all             postgres                                peer\n...\n</code></pre> <p>Change the last section of the above line to <code>md5</code>.</p> <pre><code>local   all             postgres                                md5\n</code></pre> <p>A restart is required in order to apply the new configuration:</p> <pre><code>sudo systemctl restart postgresql\n</code></pre> <p>Now a connection from outside the database host is possible e.g.</p> <pre><code>psql -U postgres -d postgres -h databasehostname\n</code></pre>"},{"location":"databases/postgres/#creation-of-additional-database-users","title":"Creation of additional database users","text":"<p>A database user can be created by the following command:</p> <pre><code>create user myuser with encrypted password 'Supersecret';\nCREATE ROLE\n\npostgres=# \\du\n                                   List of roles\n Role name |                         Attributes                         | Member of\n-----------+------------------------------------------------------------+-----------\n myuser    |                                                            | {}\n postgres  | Superuser, Create role, Create DB, Replication, Bypass RLS | {}\n</code></pre>"},{"location":"databases/postgres/#creation-of-additional-databases","title":"Creation of additional databases","text":"<p>One can create new Postgres databases within an instance. Therefore you can use the <code>psql</code> command to login (see above).</p> <pre><code>CREATE DATABASE dbname OWNER myuser;\nCREATE DATABASE\n\npostgres=# \\l\n                                  List of databases\n   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges\n-----------+----------+----------+-------------+-------------+-----------------------\n dbname    | myuser   | UTF8     | en_US.UTF-8 | en_US.UTF-8 |\n postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |\n template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +\n           |          |          |             |             | postgres=CTc/postgres\n template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +\n           |          |          |             |             | postgres=CTc/postgres\n</code></pre> <p>You can leave the <code>OWNER</code> section of the command, when doing so, the current user will become owner of the newly created database.</p> <p>To change the owner of an existing database later, you can use the following command:</p> <pre><code>postgres=# alter database dbname owner to myuser;\nALTER DATABASE\n</code></pre>"},{"location":"databases/postgres/#backup-and-restore","title":"Backup and Restore","text":"<p>There are near to endless combinations in tools and parameters to backup postgres databases. Below you can find some examples using the Postgres built-in tools <code>pgdump</code>, <code>pg_basebackup</code> and <code>pg_restore</code>.</p>"},{"location":"databases/postgres/#pg_dump-pg_dumpall","title":"pg_dump / pg_dumpall","text":"<p>Using <code>pg_dump</code> or <code>pg_dumpall</code> enables you to extract / export a PostgreSQL database(s) into a (SQL) script file or a custom archive file.</p>"},{"location":"databases/postgres/#pg_dump","title":"pg_dump","text":"<p>The following command creates a custom archive file from a database specified with <code>-d</code>. To export data in custom format, you have to specify so with the <code>-F c</code> option. Custom file dumps have the benefit, that they are compressed by default.</p> <pre><code>Using the `--create` option will include the SQL commands in the dump script that will create the database before importing it later. The `-Z 9` option in this example compresses the SQL script created with the highest available compression rate (`0-9`).\n\n```bash\npg_dump -h vmdocker -U awx -d awx --create -f -Z 9 /tmp/awx_dump.sql.gz\n</code></pre> <p>The following command creates a custom archive file from a database specified with <code>-d</code>. To export data in custom format, you have to specify so with the <code>-F c</code> option. Custom file dumps have the benefit, that they are compressed by default.</p> <pre><code>pg_dump -h {pg_host} -U {username} -d {database} -F c -f /pg_dump/dumpfile.dmp\n</code></pre> <p>Custom format files can only be restored by <code>pg_restore</code> (see below). A SQL dump can be restored by using <code>psql</code>.</p> <pre><code>psql -d newdb -f db.sql\n</code></pre> <p>A complete guide of <code>pg_dump</code> from the official documentation can be found here.</p>"},{"location":"databases/postgres/#pg_dumpall","title":"pg_dumpall","text":"<p>A full dump of all databases of a Postgres instance can be done by <code>pg_dumpall</code>. It will include also user creation information. A difference to <code>pg_dump</code>, you cannot choose for different output formats. <code>pg_dumpall</code> will always create a SQL script as output. Therefore, you don't need <code>pg_restore</code> for restoring a \"full\" dump. Only <code>psql</code> is needed (see below).</p> <pre><code>pg_dumpall -h {pg_host} -U postgres &gt; database.out\n</code></pre> <p>If you use password authentication it will ask for a password each time. It is convenient to have a <code>~/.pgpass</code> file or <code>PGPASSWORD</code> environment variable set.</p> <p>So importing a full dump is really easy by the following <code>psql</code> command:</p> <pre><code>psql -h {pg_host} -f databaseb.out -U postgres\n</code></pre> <p>A complete guide of <code>pg_dumpall</code> from the official documentation can be found here.</p>"},{"location":"databases/postgres/#pg_restore","title":"pg_restore","text":"<p><code>pg_restore</code> can be used to restore custom file dumps created by <code>pg_dump</code>.</p> <p>The following command will create the database (which has been dumped before).</p> <pre><code>pg_restore -h {pg_host} -U {pg_user} -d postgres --create -F c /tmp/db.dmp -v\n</code></pre> <p>A complete guide of <code>pg_restore</code> from the official documentation can be found here.</p>"},{"location":"databases/sqlite/","title":"SQLite Cheat-Sheet","text":"<p>SQLite is a relational database contained in a C library. In contrast to many other databases, SQLite is not a client-server database engine. Rather, it's embedded into an end program.</p> <p>SQLite generally follows the PostgreSQL syntax but does not enforce type checking.</p> <p>You can open a SQLite Database with <code>sqlite3 &lt;filename&gt;</code> directly.</p>"},{"location":"databases/sqlite/#commands","title":"Commands","text":"<p><code>.help</code> Shows all commands <code>.databases</code> Show all existing databases <code>.quit</code> Exists <code>.tables</code> Shows all tables <code>.backup</code> Backups current database</p>"},{"location":"docker/docker-compose/","title":"Docker-Compose","text":"<p>...</p>"},{"location":"docker/docker-compose/#networking","title":"Networking","text":"<p>By default Docker-Compose will create a new network for the given compose file. You can change the behavior by defining custom networks in your compose file.</p>"},{"location":"docker/docker-compose/#create-and-assign-custom-network","title":"Create and assign custom network","text":"<p>... Example:</p> <pre><code>networks:\n  custom-network:\n\nservices:\n  app:\n    networks:\n      - custom-network\n</code></pre>"},{"location":"docker/docker-compose/#use-existing-networks","title":"Use existing networks","text":"<p>If you want to use an existing Docker network for your compose files, you can add the <code>external: true</code> parameter in your compose file Example:</p> <pre><code>networks:\n  existing-network:\n    external: true\n</code></pre>"},{"location":"docker/docker-compose/#volumes","title":"Volumes","text":"<p>Volumes are data storage objects that Docker containers can use for persistent storage.</p>"},{"location":"docker/docker-compose/#create-and-map-static-volumes","title":"Create and map static volume(s)","text":"<pre><code>volumes:\n  my-volume:\n\nservices:\n  app:\n    volumes:\n      - my-volume:/path-in-container\n</code></pre> <p>These volumes are stored in <code>/var/lib/docker/volumes</code>.</p>"},{"location":"docker/docker-compose/#create-volume-that-is-a-cifs-mount-to-external-share","title":"Create volume that is a CIFS mount to external share","text":"<pre><code># Variables that will need to be changed:  \n# &lt;PUID&gt; - User id for folder/file permissions  \n# &lt;PGID&gt; - Group id for folder/file permissions  \n# &lt;PATH_TO_CONFIG&gt; - Path where Unmanic will store config files  \n# &lt;PATH_TO_ENCODE_CACHE&gt; - Cache path for in-progress encoding tasks  \n# &lt;REMOTE_IP&gt; - Remote IP address of CIFS mount  \n# &lt;PATH_TO_LIBRARY&gt; - Path in remote machine to be mounted as your library  \n# &lt;USERNAME&gt; - Remote mount username  \n# &lt;PASSWORD&gt; - Remote mount password  \n#\n\n---  \nversion: '2.4'  \nservices:  \n  app:\n    container_name: app_name  \n    image: repo/app:tag  \n    ports:  \n      - 1234:1234\n    environment:  \n      - PUID=&lt;PUID&gt;  \n      - PGID=&lt;PGID&gt;  \n    volumes:\n      - cifs_mount:/path-in-container\n\nvolumes:  \n  cifs_mount:  \n    driver: local  \n    driver_opts:  \n      type: cifs  \n      device: //&lt;REMOTE_IP&gt;/&lt;PATH_TO_LIBRARY&gt;  \n      o: \"username=&lt;USERNAME&gt;,password=&lt;PASSWORD&gt;,vers=3.0,uid=&lt;PUID&gt;,gid=&lt;PGID&gt;\"\n</code></pre>"},{"location":"docker/docker-compose/#environment-variables","title":"Environment Variables","text":"<p>Environment variables can be defined in the <code>environment</code> section of a service in a Docker Compose file.</p>"},{"location":"docker/docker-compose/#define-environment-variables","title":"Define environment variables","text":"<pre><code>services:\n  app:\n    environment:\n      - ENV_VAR=value\n</code></pre>"},{"location":"docker/docker-compose/#interpolate-environment-variables","title":"Interpolate environment variables","text":"Variable Description <code>${ENV_VAR}</code> Value of <code>ENV_VAR</code> <code>${ENV_VAR:-default}</code> Value of <code>ENV_VAR</code> if set and non-empty, otherwise <code>default</code> <code>${ENV_VAR-default}</code> Value of <code>ENV_VAR</code> if set, otherwise <code>default</code> <code>${ENV_VAR:?error}</code> Value of <code>ENV_VAR</code> if set and non-empty, otherwise exit with <code>error</code> <code>${ENV_VAR?error}</code> Value of <code>ENV_VAR</code> if set, otherwise exit with <code>error</code> <code>${ENV_VAR:+replacement}</code> <code>replacement</code> if <code>ENV_VAR</code> is set and non-empty, otherwise empty <code>${ENV_VAR+replacement}</code> <code>replacement</code> if <code>ENV_VAR</code> is set, otherwise empty"},{"location":"docker/docker-desktop/","title":"Docker Desktop","text":"<p>Docker Desktop is a software application that enables developers to build, package, and run applications using Docker containers on their local machines. It provides an easy-to-use graphical interface and includes the necessary tools and components for managing Docker containers, such as the Docker engine, images, and networking capabilities.</p>"},{"location":"docker/docker-desktop/#installing-docker-desktop","title":"Installing Docker Desktop","text":"<p>Docker Desktop is available for Windows and macOS. You can download the installer from the Docker website.</p>"},{"location":"docker/docker-desktop/#troubleshooting","title":"Troubleshooting","text":"<p>The <code>com.docker.diagnose check</code> command can be used to run a diagnostic check on Docker Desktop for Mac.</p> <pre><code>/Applications/Docker.app/Contents/MacOS/com.docker.diagnose check\n</code></pre>"},{"location":"docker/docker-file/","title":"Dockerfile","text":""},{"location":"docker/docker-file/#what-is-a-dockerfile","title":"What is a Dockerfile?","text":"<p>Docker builds images automatically by reading the instructions from a Dockerfile which is a text file that contains all commands, in order, needed to build a given image. A Dockerfile adheres to a specific format and set of instructions which you can find at Dockerfile reference.</p> <p>A Docker image consists of read-only layers each of which represents a Dockerfile instruction. The layers are stacked and each one is a delta of the changes from the previous layer.</p> <pre><code># syntax=docker/dockerfile:1\n\nFROM ubuntu:22.04\nCOPY . /app\nRUN make /app\nCMD python /app/app.py\n</code></pre> <p>In the example above, each instruction creates one layer:</p> <ul> <li>FROM creates a layer from the ubuntu:22.04 Docker image.</li> <li>COPY adds files from your Docker client's current directory.</li> <li>RUN builds your application with make.</li> <li>CMD specifies what command to run within the container.</li> </ul>"},{"location":"docker/docker-file/#buildkits","title":"BuildKits","text":"<p>BuildKit supports loading frontends dynamically from container images. To use an external Dockerfile frontend, the first line of your Dockerfile needs to set the syntax directive pointing to the specific image you want to use:</p> <pre><code># syntax=docker/dockerfile:1\n</code></pre>"},{"location":"docker/docker-file/#new-feature-in-14-here-documents","title":"New feature in 1.4 Here-Documents","text":"<pre><code>RUN &lt;&lt;EOF\napt-get update\napt-get upgrade -y\napt-get install -y ...\nEOF\n</code></pre>"},{"location":"docker/docker-file/#example-running-a-multi-line-script-python","title":"Example running a multi-line script (Python)","text":"<pre><code># syntax=docker/dockerfile:1\nFROM debian\nRUN &lt;&lt;EOT bash\n  set -ex\n  apt-get update\n  apt-get install -y vim\nEOT\n</code></pre>"},{"location":"docker/docker-file/#multi-stage-dockerfile-example-springboot","title":"Multi-Stage Dockerfile Example (SpringBoot)","text":"<pre><code># syntax=docker/dockerfile:1\n#Start with a base image containing Maven &amp; Java runtime\nFROM maven:3.9.6-eclipse-temurin-21-alpine7 AS build\n\n#Information about who maintains the image\nMAINTAINER John Doe\n\nENV HOME=/home/app\nCOPY src /home/app/src\nCOPY pom.xml $HOME\nRUN mkdir -p /root/.m2 \\\n    &amp;&amp; mkdir /root/.m2/repository\n\n# Subsequent runs will use local dependencies and execute much faster. (https://www.baeldung.com/ops/docker-cache-maven-dependencies)\nRUN --mount=type=cache,target=/root/.m2 mvn -f $HOME/pom.xml clean package -DskipTests\n\n#\n# Package stage\n#\nFROM clipse-temurin:21.0.2_13-jre-alpine\nVOLUME /tmp\nRUN groupadd -r -g 2000 mygroup &amp;&amp; useradd -m -d /home/myuser -u 2000 -r -g mygroup myuser\n\n# Add the application's jar to the container\nCOPY --from=build ${HOME}/target/demo-0.0.1-SNAPSHOT.jar /usr/local/lib/demo.jar\nUSER myuser\nEXPOSE 8080\n\n#execute the application\nENTRYPOINT [\"java\",\"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"/usr/local/lib/demo.jar\"]\n</code></pre>"},{"location":"docker/docker/","title":"Docker","text":"<p>Docker is a containerization platform that encapsulates an application and its dependencies into a container, ensuring consistent operation across different computing environments. It leverages OS-level virtualization to deliver software in packages called containers, providing isolation and resource efficiency, and facilitating CI/CD practices by streamlining deployment and scaling.</p>"},{"location":"docker/docker/#installation","title":"Installation","text":"<p>Docker can be installed on different operating systems. For local workstations, Docker Desktop is the recommended installation. For servers, Docker Engine is the recommended installation.</p>"},{"location":"docker/docker/#docker-desktop","title":"Docker Desktop","text":"<p>Docker Desktop is a software application that enables developers to build, package, and run applications using Docker containers on their local machines. It provides an easy-to-use graphical interface and includes the necessary tools and components for managing Docker containers, such as the Docker engine, images, and networking capabilities.</p> <p>For more information, see Docker Desktop</p>"},{"location":"docker/docker/#install-docker-engine","title":"Install Docker Engine","text":"<p>One click installation script:</p> <pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n</code></pre> <p>Run docker as non root user:</p> <pre><code>sudo groupadd docker\nsudo usermod -aG docker $USER\n</code></pre> <p>For more information, see Install Docker Engine</p>"},{"location":"docker/docker/#using-docker","title":"Using Docker","text":""},{"location":"docker/docker/#running-containers","title":"Running Containers","text":"COMMAND DESCRIPTION <code>docker run &lt;image&gt;</code> Start a new container from an image <code>docker run -it &lt;image&gt;</code> Start a new container in interactive mode <code>docker create &lt;image&gt;</code> Create a new container <code>docker start &lt;container&gt;</code> Start a container <code>docker stop &lt;container&gt;</code> Graceful stop a container <code>docker kill &lt;container&gt;</code> Kill (SIGKILL) a container <code>docker restart &lt;container&gt;</code> Graceful stop and restart a container <code>docker pause &lt;container&gt;</code> Suspend a container <code>docker unpause &lt;container&gt;</code> Resume a container <code>docker rm &lt;container&gt;</code> Destroy a container"},{"location":"docker/docker/#container-bulk-management","title":"Container Bulk Management","text":"COMMAND DESCRIPTION <code>docker stop $(docker ps -q)</code> To stop all the running containers <code>docker stop $(docker ps -a -q)</code> To stop all the stopped and running containers <code>docker kill $(docker ps -q)</code> To kill all the running containers <code>docker kill $(docker ps -a -q)</code> To kill all the stopped and running containers <code>docker restart $(docker ps  -q)</code> To restart all  running containers <code>docker restart $(docker ps -a -q)</code> To restart all the stopped and running containers <code>docker rm $(docker ps  -q)</code> To destroy all running containers <code>docker rm $(docker ps -a -q)</code> To destroy all the stopped and running containers <code>docker pause $(docker ps  -q)</code> To pause all  running containers <code>docker pause $(docker ps -a -q)</code> To pause all the stopped and running containers <code>docker start $(docker ps  -q)</code> To start all  running containers <code>docker start $(docker ps -a -q)</code> To start all the stopped and running containers <code>docker rm -vf $(docker ps -a -q)</code> To delete all containers including its volumes use <code>docker rmi -f $(docker images -a -q)</code> To delete all the images <code>docker system prune</code> To delete all dangling and unused images, containers, cache and volumes <code>docker system prune -a</code> To delete all used and unused images <code>docker system prune --volumes</code> To delete all docker volumes"},{"location":"docker/docker/#inspect-containers","title":"Inspect Containers","text":"COMMAND DESCRIPTION <code>docker ps</code> List running containers <code>docker ps --all</code> List all containers, including stopped <code>docker logs &lt;container&gt;</code> Show a container output <code>docker logs -f &lt;container&gt;</code> Follow a container output <code>docker top &lt;container&gt;</code> List the processes running in a container <code>docker diff</code> Show the differences with the image (modified files) <code>docker inspect</code> Show information of a container (json formatted)"},{"location":"docker/docker/#executing-commands","title":"Executing Commands","text":"COMMAND DESCRIPTION <code>docker attach &lt;container&gt;</code> Attach to a container <code>docker cp &lt;container&gt;:&lt;container-path&gt; &lt;host-path&gt;</code> Copy files from the container <code>docker cp &lt;host-path&gt; &lt;container&gt;:&lt;container-path&gt;</code> Copy files into the container <code>docker export &lt;container&gt;</code> Export the content of the container (tar archive) <code>docker exec &lt;container&gt;</code> Run a command inside a container <code>docker exec -it &lt;container&gt; /bin/bash</code> Open an interactive shell inside a container (there is no bash in some <code>docker wait &lt;container&gt;</code> Wait until the container terminates and return the exit code"},{"location":"docker/docker/#images","title":"Images","text":"COMMAND DESCRIPTION <code>docker image ls</code> List all local images <code>docker history &lt;image&gt;</code> Show the image history <code>docker inspect &lt;image&gt;</code> Show information (json formatted) <code>docker tag &lt;image&gt; &lt;tag&gt;</code> Tag an image <code>docker commit &lt;container&gt; &lt;image&gt;</code> Create an image (from a container) <code>docker import &lt;url&gt;</code> Create an image (from a tarball) <code>docker rmi &lt;image&gt;</code> Delete images <code>docker pull &lt;user&gt;/&lt;repository&gt;:&lt;tag&gt;</code> Pull an image from a registry <code>docker push &lt;user&gt;/&lt;repository&gt;:&lt;tag&gt;</code> Push and image to a registry <code>docker search &lt;test&gt;</code> Search an image on the official registry <code>docker login</code> Login to a registry <code>docker logout</code> Logout from a registry <code>docker save &lt;user&gt;/&lt;repository&gt;:&lt;tag&gt;</code> Export an image/repo as a tarball <code>docker load</code> Load images from a tarball"},{"location":"docker/docker/#volumes","title":"Volumes","text":"COMMAND DESCRIPTION <code>docker volume ls</code> List all vol1umes <code>docker volume create &lt;volume&gt;</code> Create a volume <code>docker volume inspect &lt;volume&gt;</code> Show information (json formatted) <code>docker volume rm &lt;volume&gt;</code> Destroy a volume <code>docker volume ls --filter=\"dangling=true\"</code> List all dangling volumes (not referenced by any container) <code>docker volume prune</code> Delete all volumes (not referenced by any container)"},{"location":"docker/docker/#backup-a-container","title":"Backup a container","text":"<p>Backup docker data from inside container volumes and package it in a tarball archive. <code>docker run --rm --volumes-from &lt;container&gt; -v $(pwd):/backup busybox tar cvfz /backup/backup.tar &lt;container-path&gt;</code></p> <p>An automated backup can be done also by this Ansible playbook. The output is also a (compressed) tar. The playbook can also manage the backup retention. So older backups will get deleted automatically.</p> <p>To also create and backup the container configuration itself, you can use <code>docker-replay</code>for that. If you lose the entire container, you can recreate it with the export from <code>docker-replay</code>. A more detailed tutorial on how to use docker-replay can be found here.</p>"},{"location":"docker/docker/#restore-container-from-backup","title":"Restore container from backup","text":"<p>Restore the volume with a tarball archive. <code>docker run --rm --volumes-from &lt;container&gt; -v $(pwd):/backup busybox sh -c \"cd &lt;container-path&gt; &amp;&amp; tar xvf /backup/backup.tar --strip 1\"</code></p>"},{"location":"docker/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"docker/docker/#networking","title":"Networking","text":"<p><code>docker run --name netshoot --rm -it nicolaka/netshoot /bin/bash</code></p>"},{"location":"linux/arp/","title":"ARP in Linux","text":"<p>The arp command in Linux allows you to view and modify the ARP table, which contains information about devices on the local network. It can be used to view the IP addresses and MAC addresses of devices on the network, and to add or remove entries from the ARP table.</p> Command Description <code>arp</code> View the ARP table <code>arp -a</code> View the ARP table <code>arp -n</code> View the ARP table (don't resolve names) <code>arp -d &lt;ip-address&gt;</code> Delete an entry from the ARP table <code>arp -s &lt;ip-address&gt; &lt;mac-address&gt;</code> Add an entry to the ARP table"},{"location":"linux/awk/","title":"AWK","text":"<p>AWK (awk) is a domain-specific language designed for text processing and typically used as a data extraction and reporting tool. Similar to the Sed and Grep commands, it is a filter, and is a standard feature of most Unix-like operating systems, like Linux.</p>"},{"location":"linux/awk/#usage","title":"Usage","text":""},{"location":"linux/awk/#unixlinux","title":"Unix/Linux","text":"<pre><code>awk '/pattern/ {print \"$1\"}'    # standard Unix shells\n</code></pre>"},{"location":"linux/awk/#doswin","title":"DOS/Win","text":"<pre><code>awk '/pattern/ {print \"$1\"}'    # compiled with DJGPP, Cygwin\nawk \"/pattern/ {print \\\"$1\\\"}\"  # GnuWin32, UnxUtils, Mingw\n</code></pre> <p>Note that the DJGPP compilation (for DOS or Windows-32) permits an awk script to follow Unix quoting syntax <code>'/like/ {\"this\"}'</code>. HOWEVER, if the command interpreter is <code>CMD.EXE</code> or <code>COMMAND.COM</code>, single quotes will not protect the redirection arrows <code>(&lt;, &gt;)</code> nor do they protect pipes <code>(|)</code>. These are special symbols which require \"double quotes\" to protect them from interpretation as operating system directives. If the command interpreter is bash, ksh, zsh or another Unix shell, then single and double quotes will follow the standard Unix usage.</p> <p>Users of MS-DOS or Microsoft Windows must remember that the percent sign <code>(%)</code> is used to indicate environment variables, so this symbol must be doubled <code>(%%)</code> to yield a single percent sign visible to awk.</p> <p>To conserve space, use <code>'1'</code> instead of <code>'{print}'</code> to print each line. Either one will work.</p>"},{"location":"linux/awk/#handy-one-line-awk-scripts","title":"Handy one-line Awk scripts","text":""},{"location":"linux/awk/#file-spacing","title":"File Spacing","text":"<pre><code> # double space a file\n awk '1;{print \"\"}'\n awk 'BEGIN{ORS=\"\\n\\n\"};1'\n\n # double space a file which already has blank lines in it. Output file\n # should contain no more than one blank line between lines of text.\n # NOTE: On Unix systems, DOS lines which have only CRLF (\\r\\n) are\n # often treated as non-blank, and thus 'NF' alone will return TRUE.\n awk 'NF{print $0 \"\\n\"}'\n\n # triple space a file\n awk '1;{print \"\\n\"}'\n</code></pre>"},{"location":"linux/awk/#numbering-and-calculations","title":"Numbering and Calculations","text":"<pre><code> # precede each line by its line number FOR THAT FILE (left alignment).\n # Using a tab (\\t) instead of space will preserve margins.\n awk '{print FNR \"\\t\" $0}' files*\n\n # precede each line by its line number FOR ALL FILES TOGETHER, with tab.\n awk '{print NR \"\\t\" $0}' files*\n\n # number each line of a file (number on left, right-aligned)\n # Double the percent signs if typing from the DOS command prompt.\n awk '{printf(\"%5d : %s\\n\", NR,$0)}'\n\n # number each line of file, but only print numbers if line is not blank\n # Remember caveats about Unix treatment of \\r (mentioned above)\n awk 'NF{$0=++a \" :\" $0};1'\n awk '{print (NF? ++a \" :\" :\"\") $0}'\n\n # count lines (emulates \"wc -l\")\n awk 'END{print NR}'\n\n # print the sums of the fields of every line\n awk '{s=0; for (i=1; i&lt;=NF; i++) s=s+$i; print s}'\n\n # add all fields in all lines and print the sum\n awk '{for (i=1; i&lt;=NF; i++) s=s+$i}; END{print s}'\n\n # print every line after replacing each field with its absolute value\n awk '{for (i=1; i&lt;=NF; i++) if ($i &lt; 0) $i = -$i; print }'\n awk '{for (i=1; i&lt;=NF; i++) $i = ($i &lt; 0) ? -$i : $i; print }'\n\n # print the total number of fields (\"words\") in all lines\n awk '{ total = total + NF }; END {print total}' file\n\n # print the total number of lines that contain \"Beth\"\n awk '/Beth/{n++}; END {print n+0}' file\n\n # print the largest first field and the line that contains it\n # Intended for finding the longest string in field #1\n awk '$1 &gt; max {max=$1; maxline=$0}; END{ print max, maxline}'\n\n # print the number of fields in each line, followed by the line\n awk '{ print NF \":\" $0 } '\n\n # print the last field of each line\n awk '{ print $NF }'\n\n # print the last field of the last line\n awk '{ field = $NF }; END{ print field }'\n\n # print every line with more than 4 fields\n awk 'NF &gt; 4'\n\n # print every line where the value of the last field is &gt; 4\n awk '$NF &gt; 4'\n</code></pre>"},{"location":"linux/awk/#string-creation","title":"String Creation","text":"<pre><code> # create a string of a specific length (e.g., generate 513 spaces)\n awk 'BEGIN{while (a++&lt;513) s=s \" \"; print s}'\n\n # insert a string of specific length at a certain character position\n # Example: insert 49 spaces after column #6 of each input line.\n gawk --re-interval 'BEGIN{while(a++&lt;49)s=s \" \"};{sub(/^.{6}/,\"&amp;\" s)};1'\n</code></pre>"},{"location":"linux/awk/#array-creation","title":"Array Creation","text":"<pre><code> # These next 2 entries are not one-line scripts, but the technique\n # is so handy that it merits inclusion here.\n\n # create an array named \"month\", indexed by numbers, so that month[1]\n # is 'Jan', month[2] is 'Feb', month[3] is 'Mar' and so on.\n split(\"Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\", month, \" \")\n\n # create an array named \"mdigit\", indexed by strings, so that\n # mdigit[\"Jan\"] is 1, mdigit[\"Feb\"] is 2, etc. Requires \"month\" array\n for (i=1; i&lt;=12; i++) mdigit[month[i]] = i\n</code></pre>"},{"location":"linux/awk/#text-conversion-and-substitution","title":"Text Conversion and Substitution","text":"<pre><code> # IN UNIX ENVIRONMENT: convert DOS newlines (CR/LF) to Unix format\n awk '{sub(/\\r$/,\"\")};1'   # assumes EACH line ends with Ctrl-M\n\n # IN UNIX ENVIRONMENT: convert Unix newlines (LF) to DOS format\n awk '{sub(/$/,\"\\r\")};1'\n\n # IN DOS ENVIRONMENT: convert Unix newlines (LF) to DOS format\n awk 1\n\n # IN DOS ENVIRONMENT: convert DOS newlines (CR/LF) to Unix format\n # Cannot be done with DOS versions of awk, other than gawk:\n gawk -v BINMODE=\"w\" '1' infile &gt;outfile\n\n # Use \"tr\" instead.\n tr -d \\r &lt;infile &gt;outfile            # GNU tr version 1.22 or higher\n\n # delete leading whitespace (spaces, tabs) from front of each line\n # aligns all text flush left\n awk '{sub(/^[ \\t]+/, \"\")};1'\n\n # delete trailing whitespace (spaces, tabs) from end of each line\n awk '{sub(/[ \\t]+$/, \"\")};1'\n\n # delete BOTH leading and trailing whitespace from each line\n awk '{gsub(/^[ \\t]+|[ \\t]+$/,\"\")};1'\n awk '{$1=$1};1'           # also removes extra space between fields\n\n # insert 5 blank spaces at beginning of each line (make page offset)\n awk '{sub(/^/, \"     \")};1'\n\n # align all text flush right on a 79-column width\n awk '{printf \"%79s\\n\", $0}' file*\n\n # center all text on a 79-character width\n awk '{l=length();s=int((79-l)/2); printf \"%\"(s+l)\"s\\n\",$0}' file*\n\n # substitute (find and replace) \"foo\" with \"bar\" on each line\n awk '{sub(/foo/,\"bar\")}; 1'           # replace only 1st instance\n gawk '{$0=gensub(/foo/,\"bar\",4)}; 1'  # replace only 4th instance\n awk '{gsub(/foo/,\"bar\")}; 1'          # replace ALL instances in a line\n\n # substitute \"foo\" with \"bar\" ONLY for lines which contain \"baz\"\n awk '/baz/{gsub(/foo/, \"bar\")}; 1'\n\n # substitute \"foo\" with \"bar\" EXCEPT for lines which contain \"baz\"\n awk '!/baz/{gsub(/foo/, \"bar\")}; 1'\n\n # change \"scarlet\" or \"ruby\" or \"puce\" to \"red\"\n awk '{gsub(/scarlet|ruby|puce/, \"red\")}; 1'\n\n # reverse order of lines (emulates \"tac\")\n awk '{a[i++]=$0} END {for (j=i-1; j&gt;=0;) print a[j--] }' file*\n\n # if a line ends with a backslash, append the next line to it (fails if\n # there are multiple lines ending with backslash...)\n awk '/\\\\$/ {sub(/\\\\$/,\"\"); getline t; print $0 t; next}; 1' file*\n\n # print and sort the login names of all users\n awk -F \":\" '{print $1 | \"sort\" }' /etc/passwd\n\n # print the first 2 fields, in opposite order, of every line\n awk '{print $2, $1}' file\n\n # switch the first 2 fields of every line\n awk '{temp = $1; $1 = $2; $2 = temp}' file\n\n # print every line, deleting the second field of that line\n awk '{ $2 = \"\"; print }'\n\n # print in reverse order the fields of every line\n awk '{for (i=NF; i&gt;0; i--) printf(\"%s \",$i);print \"\"}' file\n\n # concatenate every 5 lines of input, using a comma separator\n # between fields\n awk 'ORS=NR%5?\",\":\"\\n\"' file\n</code></pre>"},{"location":"linux/awk/#selective-printing-of-certain-lines","title":"Selective Printing of Certain Lines","text":"<pre><code> # print first 10 lines of file (emulates behavior of \"head\")\n awk 'NR &lt; 11'\n\n # print first line of file (emulates \"head -1\")\n awk 'NR&gt;1{exit};1'\n\n  # print the last 2 lines of a file (emulates \"tail -2\")\n awk '{y=x \"\\n\" $0; x=$0};END{print y}'\n\n # print the last line of a file (emulates \"tail -1\")\n awk 'END{print}'\n\n # print only lines which match regular expression (emulates \"grep\")\n awk '/regex/'\n\n # print only lines which do NOT match regex (emulates \"grep -v\")\n awk '!/regex/'\n\n # print any line where field #5 is equal to \"abc123\"\n awk '$5 == \"abc123\"'\n\n # print only those lines where field #5 is NOT equal to \"abc123\"\n # This will also print lines which have less than 5 fields.\n awk '$5 != \"abc123\"'\n awk '!($5 == \"abc123\")'\n\n # matching a field against a regular expression\n awk '$7  ~ /^[a-f]/'    # print line if field #7 matches regex\n awk '$7 !~ /^[a-f]/'    # print line if field #7 does NOT match regex\n\n # print the line immediately before a regex, but not the line\n # containing the regex\n awk '/regex/{print x};{x=$0}'\n awk '/regex/{print (NR==1 ? \"match on line 1\" : x)};{x=$0}'\n\n # print the line immediately after a regex, but not the line\n # containing the regex\n awk '/regex/{getline;print}'\n\n # grep for AAA and BBB and CCC (in any order on the same line)\n awk '/AAA/ &amp;&amp; /BBB/ &amp;&amp; /CCC/'\n\n # grep for AAA and BBB and CCC (in that order)\n awk '/AAA.*BBB.*CCC/'\n\n # print only lines of 65 characters or longer\n awk 'length &gt; 64'\n\n # print only lines of less than 65 characters\n awk 'length &lt; 64'\n\n # print section of file from regular expression to end of file\n awk '/regex/,0'\n awk '/regex/,EOF'\n\n # print section of file based on line numbers (lines 8-12, inclusive)\n awk 'NR==8,NR==12'\n\n # print line number 52\n awk 'NR==52'\n awk 'NR==52 {print;exit}'          # more efficient on large files\n\n # print section of file between two regular expressions (inclusive)\n awk '/Iowa/,/Montana/'             # case sensitive\n</code></pre>"},{"location":"linux/awk/#selective-deletion-of-certain-lines","title":"Selective Deletion of Certain Lines","text":"<pre><code> # delete ALL blank lines from a file (same as \"grep '.' \")\n awk NF\n awk '/./'\n\n # remove duplicate, consecutive lines (emulates \"uniq\")\n awk 'a !~ $0; {a=$0}'\n\n # remove duplicate, nonconsecutive lines\n awk '!a[$0]++'                     # most concise script\n awk '!($0 in a){a[$0];print}'      # most efficient script\n</code></pre>"},{"location":"linux/awk/#references","title":"References","text":"<p>For additional syntax instructions, including the way to apply editing commands from a disk file instead of the command line, consult:</p> <p>\"sed &amp; awk, 2nd Edition,\" by Dale Dougherty and Arnold Robbins   (O'Reilly, 1997)</p> <p>\"UNIX Text Processing,\" by Dale Dougherty and Tim O'Reilly (Hayden   Books, 1987)</p> <p>\"GAWK: Effective awk Programming,\" 3d edition, by Arnold D. Robbins   (O'Reilly, 2003) or at http://www.gnu.org/software/gawk/manual/</p> <p>To fully exploit the power of awk, one must understand \"regular expressions.\" For detailed discussion of regular expressions, see \"Mastering Regular Expressions, 3d edition\" by Jeffrey Friedl (O'Reilly, 2006).</p> <p>The info and manual (\"man\") pages on Unix systems may be helpful (try \"man awk\", \"man nawk\", \"man gawk\", \"man regexp\", or the section on regular expressions in \"man ed\").</p> <p>USE OF '\\t' IN awk SCRIPTS: For clarity in documentation, I have used '\\t' to indicate a tab character (0x09) in the scripts.  All versions of awk should recognize this abbreviation.</p>"},{"location":"linux/cron/","title":"Cron","text":"<p>A CRON expression is simply a string consisting of six fields that each define a specific unit of time.\u00a0</p> <p>They are written in the following format:</p> <pre><code>{second} {minute} {hour} {day} {month} {day of the week}\n</code></pre>"},{"location":"linux/cron/#values","title":"Values","text":"<p>The following values are allowed within each date/time unit placeholder.</p> Field Allowed Values \u00a0Description {second} 0-59 Trigger every {second} second(s) {minute} 0-59 Trigger every {minute} minute(s) {hour} 0-23 Trigger every {hour} hour(s) {day} 1-31 Trigger every {day} day(s) of month {month} 1-12 Trigger every {month} month(s) {day of week} 0-6 MON-SUN Trigger on specific"},{"location":"linux/cron/#special-characters","title":"Special Characters","text":"<p>Additionally you can also use the following special characters to build more advanced expressions:</p> Special Character Description <code>*</code> Trigger on tick of every time unit <code>,</code> List separator <code>\u2013</code> Specifies a range <code>/</code> Defines an increment"},{"location":"linux/cron/#examples","title":"Examples","text":"<p><code>0 * * * * *</code> - Executes every minute <code>0 0 * * * *</code> - Executes every hour <code>0 0 0 * * *</code> - Executes every day <code>0 0 0 0 * *</code> - Executes every month <code>0 0 0 1 1 *</code> - Executes on first day of Jan\u00a0each year <code>30 20 * * SAT</code> - Executes at 08:30pm every Saturday <code>30 20 * * 6</code> - Executes at 08:30pm every Saturday <code>0 */5 * * * *</code> - Executes every five minutes <code>0 0 8-10/1 * * *</code> - Executes every hour between 8am and 10am</p>"},{"location":"linux/environment-variables-in-linux/","title":"Environment Variables in Linux","text":""},{"location":"linux/etherwake/","title":"Etherwake","text":"<p>Etherwake is a command-line utility for sending Wake-on-LAN (WoL) magic packets to wake up a device over a network connection. It allows you to wake up a device by specifying its MAC address as an argument, and it sends the magic packet to the broadcast address of the network interface that is specified.</p> <p>Here's an example of how to use Etherwake to wake up a device with a specific MAC address:</p> <pre><code>sudo etherwake -i eth0 00:11:22:33:44:55\n</code></pre> <p>In this example, <code>sudo</code> is used to run the command with administrative privileges, <code>-i eth0</code> specifies the network interface to use (in this case, <code>eth0</code>), and <code>00:11:22:33:44:55</code> is the MAC address of the device to wake up.</p> <p>The command sends a Wake-on-LAN magic packet to the broadcast address of the <code>eth0</code> network interface, which should wake up the device with the specified MAC address if Wake-on-LAN is enabled on the device.</p> <p>Note that the exact syntax and options for <code>etherwake</code> may vary depending on your operating system and version of the utility. You can usually find more information and examples in the <code>etherwake</code> manual page (<code>man etherwake</code>).</p>"},{"location":"linux/ethtool/","title":"Ethtool","text":"<p>Ethtool is a command-line utility used in Linux systems to query and control network interface settings. It provides information about the network interface cards (NICs) installed on a system, such as link status, driver information, speed, duplex mode, and more, and allows you to modify certain settings of a network interface.</p>"},{"location":"linux/ethtool/#using-ethtool-to-view-network-interface-information","title":"Using Ethtool to view network interface information","text":"<p>To view general information about a specific network interface (e.g., eth0), use the following command:</p> <pre><code>ethtool interface_name\n</code></pre> <p>If you want to retrieve only the link status of an interface, you can use the \ufeff-i option followed by the interface name:</p> <pre><code>ethtool -i interface_name\n</code></pre>"},{"location":"linux/ethtool/#using-ethtool-to-change-network-interface-settings","title":"Using Ethtool to change network interface settings","text":"<p>Ethtool allows you to modify certain settings of a network interface. For example, you can manually set the speed and duplex mode, enable or disable features like Wake-on-LAN or autonegotiation, configure flow control settings, and adjust ring buffer sizes.</p>"},{"location":"linux/ethtool/#manually-set-the-speed-and-duplex-mode-of-a-network-interface","title":"Manually set the speed and duplex mode of a network interface","text":"<p>To manually set the speed and duplex mode of a network interface (e.g., eth0) to a specific value, use the following command:</p> <pre><code>ethtool -s interface_name speed interface_speed duplex interface_duplex\n</code></pre> <p>If you want to enable or disable autonegotiation on a specific interface, you can use the following command:</p> <pre><code>ethtool -s interface_name autoneg on\nethtool -s interface_name autoneg off\n</code></pre>"},{"location":"linux/ethtool/#enable-wake-on-lan-wol-on-the-network-adapter","title":"Enable Wake On LAN (WoL) on the network adapter","text":"<p>Use the following command to check if your network interface supports Wake On LAN (WoL):</p> <pre><code>sudo ethtool interface_name | grep \"Wake-on\"\n</code></pre> <p>If the output shows \"Wake-on: d\", it means that Wake On LAN (WoL) is disabled.</p> <p>To enable Wake On LAN (WoL), use the following command:</p> <pre><code>sudo ethtool -s interface_name wol g\n</code></pre>"},{"location":"linux/ethtool/#make-the-wake-on-lan-wol-setting-persistent-across-reboots","title":"Make the Wake On LAN (WoL) setting persistent across reboots","text":"<p>To make the Wake On LAN (WoL) setting persistent across reboots, add the following line to the <code>/etc/network/interfaces</code> file:</p> <pre><code>post-up /usr/sbin/ethtool -s interface_name wol g\n</code></pre>"},{"location":"linux/grep/","title":"Grep","text":"<p>Grep is a command-line utility for searching plain-text data sets for lines that match a regular expression. Its name comes from the ed command g/re/p (globally search for a regular expression and print matching lines), which has the same effect. grep was originally developed for the Unix operating system like Linux ([[linux]]), but later available for all Unix-like systems and some others such as OS-9.</p>"},{"location":"linux/iptables/","title":"IPTables","text":"<p>Iptables is a user-space utility program that allows a system administrator to configure the IP packet filter rules of the Linux ([[linux]]) kernel firewall, implemented as different Netfilter modules. The filters are organized in different tables, which contain chains of rules for how to treat network traffic packets. Different kernel modules and programs are currently used for different protocols; iptables applies to IPv4, ip6tables to IPv6, arptables to ARP, and ebtables to Ethernet frames.</p>"},{"location":"linux/lspci/","title":"LSPCI","text":"<p>Lspci is a command-line utility in Linux and Unix operating systems that is used to display information about all the PCI (Peripheral Component Interconnect) buses and devices connected to the system. It provides detailed information about the hardware components, including their vendor and device IDs, subsystems, and other attributes. The lspci command is often used for diagnosing hardware-related issues and identifying the specific hardware components installed in a system.</p>"},{"location":"linux/lspci/#how-to-use-lspci","title":"How to use LSPCI","text":"<p>Here is an example of using the \ufefflspci command in a Linux terminal:</p> <pre><code>$ lspci\n00:00.0 Host bridge: Intel Corporation 8th Gen Core Processor Host Bridge/DRAM Registers (rev 07)\n00:01.0 PCI bridge: Intel Corporation Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Controller (x16) (rev 07)\n00:02.0 VGA compatible controller: Intel Corporation UHD Graphics 630 (Desktop)\n00:08.0 System peripheral: Intel Corporation Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th/8th Gen Core Processor Gaussian Mixture Model\n00:14.0 USB controller: Intel Corporation 200 Series/Z370 Chipset Family USB 3.0 xHCI Controller\n00:14.2 Signal processing controller: Intel Corporation 200 Series PCH Thermal Subsystem\n...\n</code></pre> <p>This output shows information about various hardware components in the system, including the vendor and device IDs, the device type, and the revision number.</p>"},{"location":"linux/lspci/#show-details-about-devices","title":"Show details about devices","text":"<p>To show detailed information about a specific device using \ufefflspci, you can specify the device\u2019s bus address using the \ufeff<code>lspci -s</code> option.</p> <pre><code>$ lspci -s 00:02.0\n00:02.0 VGA compatible controller: Intel Corporation UHD Graphics 630 (Desktop) (rev 02)\n        Subsystem: ASRock Incorporation Device 3977\n        Flags: bus master, fast devsel, latency 0, IRQ 131\n        Memory at a0000000 (64-bit, non-prefetchable) [size=16M]\n        Memory at 90000000 (64-bit, prefetchable) [size=256M]\n        I/O ports at 5000 [size=64]\n        [virtual] Expansion ROM at 000c0000 [disabled] [size=128K]\n        Capabilities: &lt;access denied&gt;\n        Kernel driver in use: i915\n        Kernel modules: i915\n</code></pre> <p>This output shows detailed information about the VGA compatible controller, including its subsystem, memory addresses, I/O ports, and kernel driver.</p>"},{"location":"linux/lspci/#verbose-output-of-lspci","title":"Verbose output of lspci","text":"<p>The \ufeff<code>-v</code> (verbose) and \ufeff<code>-vv</code> (very verbose) parameters in \ufefflspci are used to increase the level of detail in the output.</p> <p>\u2022 The \ufeff<code>-v</code> option provides additional information about the devices, including the vendor and device IDs, subsystem IDs, and more. \u2022 The \ufeff<code>-vv</code> option provides even more detailed information, including the device\u2019s capabilities, IRQ settings, and ASPM (Active State Power Management) settings.</p> <p>For example, to show the ASPM settings for the PCI Express device with bus address \ufeff00:1c.0, you can run the following command:</p> <pre><code>$ lspci -s 00:1c.0 -vv | grep -i aspm\n                ASPM L1 Enabled; L0s Enabled\n</code></pre>"},{"location":"linux/lspci/#most-useful-commands","title":"Most useful commands","text":"Command Description <code>lspci</code> List all PCI devices in the system. <code>lspci -v</code> List all PCI devices in the system with verbose output, including vendor and device IDs, subsystem IDs, and more. <code>lspci -vv</code> List all PCI devices in the system with very verbose output, including device capabilities, IRQ settings, and ASPM (Active State Power Management) settings. <code>lspci -s &lt;bus_address&gt;</code> Display information for a specific PCI device with the specified bus address. <code>lspci -k</code> Show kernel driver in use for each device. <code>lspci -n</code> Show numeric IDs for vendor and device instead of names. <code>lspci -nn</code> Show numeric IDs for vendor, device, subsystem vendor, and subsystem device instead of names. <code>lspci -t</code> Display a tree-like diagram of the PCI bus hierarchy. <code>lspci -D</code> Show only PCI devices that are not behind a bridge. <code>lspci -H1</code> Show device numbers in hexadecimal format instead of decimal. <code>lspci -x</code> Show hex dump of the PCI configuration space for each device."},{"location":"linux/lvm2/","title":"LVM2 (Logical Volume Manager 2)","text":"<p>LVM2 (Logical Volume Manager 2) is a utility for managing disk storage in Linux. It allows you to manage disk space efficiently by abstracting physical storage devices into logical volumes. It provides features like volume resizing, snapshotting, and striping, making it flexible and scalable for various storage needs.</p> <ol> <li> <p>Physical Volume: Represents the physical storage devices (e.g., hard drives, SSDs) that are part of the storage pool managed by LVM.</p> </li> <li> <p>Volume Group: Combines multiple physical volumes into a unified storage pool, enabling easy management and allocation of logical volumes.</p> </li> <li> <p>Logical Volume: Serves as a virtual disk that can be used for various purposes, such as creating partitions, mounting file systems, or even setting up RAID configurations.</p> </li> <li> <p>File System: Represents the data organization and access methods used to store and retrieve data on a logical volume. Common file systems include EXT4, XFS, and Btrfs.</p> </li> </ol>"},{"location":"linux/lvm2/#physical-volume-pv","title":"Physical Volume (PV)","text":"<p>A Physical Volume (PV) in LVM is a physical storage device or partition used by LVM. It is a building block for creating Volume Groups and Logical Volumes, allowing you to manage storage efficiently. This command creates the PV on the devices, you can do multiple at a time.</p> <pre><code>sudo pvcreate /dev/Device /dev/Device2\n</code></pre> <p>The <code>pvdisplay</code> command provides a output for each physical volume. It displays physical properties like size, extents, volume group, and so on in a fixed format.</p> <pre><code>sudo pvdisplay\n</code></pre> <p>The pvscan command scans all physical volumes (PVs) on the system and displays information about them.</p> <pre><code>sudo pvscan\n</code></pre> <p>Moves the allocated physical extents from one physical volume to another. Useful when you need to redistribute space between physical volumes in a volume group. After a crash or power failure this can be finished without a problem.</p> <pre><code>sudo pvmove /dev/source_device /dev/target_device\n</code></pre>"},{"location":"linux/lvm2/#volume-group-vg","title":"Volume Group (VG)","text":"<p>A Volume Group (VG) in LVM is a collection of one or more Physical Volumes (PVs) combined into a single storage pool. It allows flexible and efficient management of disk space, enabling easy allocation to Logical Volumes (LVs) as needed.</p> <p>Creates a volume group with a specified name.</p> <pre><code>sudo vgcreate Volume_Name /dev/Device1 /dev/Device2 ...\n</code></pre> <p>The <code>vgdisplay</code> command displays volume group properties (such as size, extents, number of physical volumes, and so on) in a fixed form.</p> <pre><code>sudo vgdisplay\n</code></pre> <p>The <code>vgs</code> command provides volume group information in a configurable form, displaying one line per volume group. The <code>vgs</code> command provides a great deal of format control, and is useful for scripting.</p> <pre><code>sudo vgs\n</code></pre>"},{"location":"linux/lvm2/#logical-volume-lv","title":"Logical Volume (LV)","text":"<p>A logical volume in LVM is a flexible virtual partition that separates storage management from physical disks. This creates a logical volume out of the Volume Group with the specified name and size (5GB).</p> <pre><code>sudo lvcreate -n Volume -L 5g Group\n</code></pre> <p>Extends the logical volume by all the available space from the volume group. U can also extend it to a fixed size if u don't use the <code>+</code>.</p> <pre><code>sudo lvextend -L +100%FREE Group/Volume\n</code></pre> <p>Same as above but in the other direction.</p> <pre><code>sudo lvreduce -L -5g Group/Volume\n</code></pre> <p>This is how u rename a logical volume.</p> <pre><code>sudo lvrename /dev/Group/old_LV_name new_LV_name\n</code></pre> <p>This removes a logical volume. Use this command with extreme caution, as it will permanently delete the data on the logical volume.</p> <pre><code>sudo lvremove /dev/Group/Volume\n</code></pre> <p>The <code>lvs</code> command provides logical volume information in a configurable form, displaying one line per logical volume. The <code>lvs</code> command provides a great deal of format control, and is useful for scripting.</p> <pre><code>sudo lvs\n</code></pre> <p>The <code>lvdisplay</code> command displays logical volume properties (such as size, layout, and mapping) in a fixed format.</p> <pre><code>sudo lvdisplay\n</code></pre>"},{"location":"linux/lvm2/#file-system","title":"File System","text":"<p>After extending a logical volume, use this command to expand the file system to use the new space.</p> <pre><code>sudo resize2fs /dev/Group/Volume\n</code></pre>"},{"location":"linux/lvm2/#snapshots","title":"Snapshots","text":"<p>Snapshots in LVM are copies of a logical volume at a specific time, useful for backups and data recovery. This creates a snapshot named \"snap\" with 5GB. Snapshots store only the changes made since their creation and are independent of the original volume. </p> <pre><code>sudo lvcreate -s -n snap -L 5g Group/Volume\n</code></pre> <p>Merges the snapshot with the original volume. Useful after a faulty update; requires a reboot.</p> <pre><code>sudo lvconvert --merge Group/snap\n</code></pre>"},{"location":"linux/lvm2/#cache","title":"Cache","text":"<p>This creates a cache logical volume with the \"writethrough\" cache mode using 100% of the free space. Caching improves disk read/write performance. Writethrough ensures that any data written will be stored both in the cache and on the origin LV. The loss of a device associated with the cache in this case would not mean the loss of any data. A second cache mode is \"writeback\". Writeback delays writing data blocks from the cache back to the origin LV.</p> <pre><code>sudo lvcreate --type cache --cachemode writethrough -l 100%FREE -n root_cachepool MyVolGroup/rootvol /dev/fastdisk\n</code></pre> <p>This removes the cache from the specified logical volume.</p> <pre><code>sudo lvconvert --uncache MyVolGroup/rootvol\n</code></pre>"},{"location":"linux/lvm2/#raid","title":"RAID","text":"<p>LVM Is Using md Under the Hood</p> <p>This configuring below will still use \"md\" behind the scenes. It just saves you the trouble of using \"mdadm\".</p>"},{"location":"linux/lvm2/#raid-0","title":"RAID 0","text":"<p>RAID 0 is a data storage configuration that stripes data across multiple drives to improve performance, but offers no data redundancy, meaning a single drive failure can result in data loss. This creates a RAID 0 logical volume with a specified name using 100% of the free space in the volume group, with the specified stripe size (2GB).</p> <pre><code>sudo lvcreate -i Stripes -I 2G -l 100%FREE -n Volume Group\n</code></pre>"},{"location":"linux/lvm2/#raid-1","title":"RAID 1","text":"<p>RAID 1 is a data storage configuration that mirrors data across multiple drives for data redundancy, providing fault tolerance in case of drive failure but without the performance improvement of RAID 0. This creates a RAID 1 logical volume with a specified name using 100% of the free space in the volume group. The <code>--nosync</code> option skips initial sync.</p> <pre><code>sudo lvcreate --mirrors 1 --type raid1 -l 100%FREE --nosync -n Volume VGName\n</code></pre>"},{"location":"linux/lvm2/#raid-5","title":"RAID 5","text":"<p>RAID 5 is a data storage configuration that combines striping and parity to provide both performance improvement and data redundancy, allowing for continued data access even if a single drive fails. This creates a RAID 5 logical volume with a specified name using 100% of the free space in the volume group. RAID 5 offers both data striping and parity for fault tolerance.</p> <pre><code>sudo lvcreate --type raid5 -l 100%FREE -n LVName VGName\n</code></pre>"},{"location":"linux/mount/","title":"Mount","text":"<p>In Linux ([[linux]]), mount is a command in various operating systems. Before a user can access a file on a Unix-like machine, the file system on the device which contains the file needs to be mounted with the mount command. Frequently mount is used for SD card, USB storage, DVD and other removable storage devices. </p> <p>List mount-points <pre><code>findmnt (optional)&lt;device/directory&gt;\n</code></pre></p> <p>Unmount <pre><code>umount &lt;device/directory&gt;\n</code></pre></p>"},{"location":"linux/netplan/","title":"Netplan","text":"<p>Netplan is a utility for configuring network interfaces in modern versions of Ubuntu and other Linux distributions. Netplan generates the corresponding configuration files for the underlying network configuration subsystem, such as systemd-networkd or NetworkManager.</p>"},{"location":"linux/netplan/#how-to-use","title":"How to use","text":"<p>Netplan uses YAML configuration files in the <code>/etc/netplan/</code> to describe network interfaces, IP addresses, routes, and other network-related parameters.</p> <p>Example: <code>/etc/netplan/01-netcfg.yaml</code> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      dhcp4: true\n</code></pre></p> <p>This configuration sets up a DHCP client for the <code>\ufeffenp0s3</code> Ethernet interface, using the \ufeffsystemd-networkd renderer. </p> <p>To apply this configuration, run the following command. </p> <pre><code>sudo netplan apply.\n</code></pre> <p>You can also test a new Netplan configuration without applying it permanently. This is useful if you want to try out a new network configuration without disrupting your current network connection.</p> <pre><code>sudo netplan try\n</code></pre>"},{"location":"linux/netplan/#static-ip-addresses","title":"Static IP addresses","text":"<p>To define a static IP address in Netplan, you can use the \ufeffaddresses key in the configuration file for the relevant network interface. Here\u2019s an example configuration file that sets a static IP address of \ufeff192.168.1.10 with a net mask of \ufeff24 bits for the <code>\ufeffenp0s3</code> Ethernet interface:</p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      addresses:\n        - 192.168.1.10/24\n      gateway4: 192.168.1.1\n      nameservers:\n        addresses: [8.8.8.8, 8.8.4.4]\n</code></pre> <p>In this configuration, the \ufeffaddresses key sets the static IP address and net mask for the <code>\ufeffenp0s3</code> interface. The \ufeffgateway4 key sets the default gateway, and the \ufeffnameserver's key sets the DNS servers.</p>"},{"location":"linux/netplan/#vlans","title":"VLANs","text":"<p>Example 1: Simple VLAN configuration <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      dhcp4: true\n  vlans:\n    vlan10:\n      id: 10\n      link: enp0s3\n      dhcp4: true\n</code></pre></p> <p>In this configuration, the <code>\ufeffenp0s3</code> Ethernet interface is configured to use DHCP to obtain an IP address. A VLAN with ID 10 is also configured on the <code>\ufeffenp0s3</code> interface, and DHCP is enabled for this VLAN as well. The \ufefflink key specifies that the VLAN is associated with the <code>\ufeffenp0s3</code> interface.</p> <p>Example 2: Advanced VLAN configuration <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      dhcp4: true\n  vlans:\n    vlan10:\n      id: 10\n      link: enp0s3\n      addresses:\n        - 192.168.10.2/24\n      routes:\n        - to: 0.0.0.0/0\n          via: 192.168.10.1\n      nameservers:\n        addresses: [8.8.8.8, 8.8.4.4]\n</code></pre></p> <p>In this configuration, a VLAN with ID 10 is configured on the <code>\ufeffenp0s3</code> interface, and a static IP address of \ufeff<code>192.168.10.2</code> with a net mask of \ufeff<code>24</code> bits is assigned to the VLAN interface. The \ufeffroutes key specifies a default route via the gateway at <code>\ufeff192.168.10.1</code>. The \ufeffnameserver's key sets the DNS servers to <code>\ufeff8.8.8.8</code> and <code>\ufeff8.8.4.4</code>.</p>"},{"location":"linux/netplan/#bridges-and-bonding","title":"Bridges and Bonding","text":"<p>Bridging and bonding are two techniques used to combine multiple network interfaces into a single logical interface.</p>"},{"location":"linux/netplan/#bonding","title":"Bonding","text":"<p>Bonding involves combining two or more physical interfaces into a single logical interface, called a bond interface. The bond interface acts like a single network interface, providing higher bandwidth and redundancy. Bonding is often used in high-performance computing environments, where multiple network interfaces are required to handle the high volume of network traffic.</p> <p>Example 1: Bonding configuration <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      dhcp4: true\n    enp0s4:\n      dhcp4: true\n  bonds:\n    bond0:\n      interfaces:\n        - enp0s3\n        - enp0s4\n      dhcp4: true\n      parameters:\n        mode: active-backup\n</code></pre></p> <p>In this configuration, two Ethernet interfaces (\ufeffenp0s3 and \ufeffenp0s4) are configured with DHCP to obtain IP addresses. A bond interface (\ufeffbond0) is also configured, which combines the two Ethernet interfaces into a single logical interface. The \ufeffinterfaces key specifies the physical interfaces to include in the bond, and the \ufeffmode key specifies the bonding mode (in this case, \ufeffactive-backup).</p>"},{"location":"linux/netplan/#bridging","title":"Bridging","text":"<p>Bridging involves creating a bridge interface that connects two or more physical interfaces. The bridge interface acts like a virtual switch, allowing devices connected to any of the physical interfaces to communicate with each other as if they were on the same network segment. Bridging is often used to connect two separate network segments or to provide redundancy in case one physical interface fails.</p> <p>Example 2: Bridging configuration <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      dhcp4: true\n    enp0s4:\n      dhcp4: true\n  bridges:\n    br0:\n      interfaces:\n        - enp0s3\n        - enp0s4\n      dhcp4: true\n</code></pre></p> <p>In this configuration, two Ethernet interfaces (\ufeffenp0s3 and \ufeffenp0s4) are configured with DHCP to obtain IP addresses. A bridge interface (\ufeffbr0) is also configured, which combines the two Ethernet interfaces into a single logical interface. The \ufeffinterfaces key specifies the physical interfaces to include in the bridge.</p>"},{"location":"linux/nfs/","title":"NFS","text":"<p>Network File System (NFS) is a distributed file system protocol originally developed by Sun Microsystems (Sun), available in Linux ([[linux]]), allowing a user on a client computer to access files over a computer network much like local storage is accessed. NFS, like many other protocols, builds on the Open Network Computing Remote Procedure Call (ONC RPC) system. NFS is an open IETF standard defined in a Request for Comments (RFC), allowing anyone to implement the protocol.</p>"},{"location":"linux/nfs/#install-nfs","title":"Install NFS","text":"<p>Install NFS Client on Ubuntu <pre><code>sudo apt -y update\nsudo apt -y install nfs-common\n</code></pre></p>"},{"location":"linux/nfs/#client-configuration","title":"Client Configuration","text":""},{"location":"linux/nfs/#server-configuration","title":"Server Configuration","text":""},{"location":"linux/nfs/#configuration","title":"Configuration","text":"<p>TEMP EXAMPLE: <code>/srv/nfs 192.168.1.2(rw,sync,no_root_squash,subtree_check)</code></p>"},{"location":"linux/nfs/#root-rw-permissions","title":"root rw permissions","text":"<p>Note the root_squash mount option. This option is set by default and must be disabled if not wanted. Fix: enable <code>no_root_squash</code>in the <code>/etc/exports</code> file and reload the permissions with <code>sudo exportfs -ra</code></p>"},{"location":"linux/sed/","title":"SED Cheat-Sheet","text":"<p>sed\u00a0(\"stream editor\") is a\u00a0Linux ([[linux]]), and Unix\u00a0utility that parses and transforms text, using a simple, compact programming language.</p> <p>TMP replace pattern:  <pre><code>sed -i 's/Steven/Kate/' file\n</code></pre></p>"},{"location":"linux/uff-tailscale-hardening/","title":"tailscale-hardening","text":"<p>Use UFW to lock down an Ubuntu server Any server on the public internet is bound to be attacked by bots looking for weak or leaked passwords and unsafely configured services. Even security experts can misconfigure a database, or an unwitting member of the team can accidentally open up a vulnerability, leaving your devices or network open to attack. If you have an existing server, you can view this bot traffic by running sudo less /var/log/auth.log. If your server is like many on the web, you'll see lots of \"invalid user admin\" or \"invalid user test\". Tailscale simplifies network security by letting you keep your servers away from the public web, while keeping it easy to connect. The best way to secure a server with Tailscale is to accept connections from Tailscale, and ignore any public internet traffic. Since your Tailscale network is invisible, except to those in your network, attackers won't even be able to find it. Prerequisites</p> <p>Before you begin this guide, you'll need an Ubuntu server to secure. This guide assumes you're setting up a DigitalOcean Ubuntu 18.04 server, but the steps should be similar for most hosting providers and versions of Ubuntu. You\u2019ll also need a Tailscale network, known as a tailnet. For information about creating a tailnet, see the Tailscale quickstart. Next, you'll need to install the Tailscale client on your local machine and log in. Download Tailscale We'll follow the same steps on the Ubuntu server next. Step 1: ssh into your new Ubuntu server</p> <p>After spinning up a new server, ssh into it with your account details.</p> <p>ssh @ Step 2: Install Tailscale on your Ubuntu server <p>Install Tailscale using the one-line script below, or read our detailed install instructions for Ubuntu</p> <p>curl -fsSL https://tailscale.com/install.sh | sh Authenticate and connect your machine to your Tailscale network</p> <p>sudo tailscale up (Optional) If you signed in with a custom domain (not a @gmail.com address) visit the admin console and authorize your new endpoint. (Optional) Disable key expiry for this server As a security feature, Tailscale requires periodic reauthentication. To prevent getting locked out, you may want to disable expiry on certain endpoints, such as this trusted server. Disable key expiry by following these instructions. If you leave key expiry on, be familiar with how to regain server access. For example, DigitalOcean provides access via a droplet console. Step 3: ssh over Tailscale</p> <p>An important step \u2014 since we're about to restrict ssh access to be only over Tailscale, we'll exit the machine and re-ssh with our Tailscale IP. First, find and copy your machine's Tailscale IP. The easiest way to do this is to run</p> <p>tailscale ip -4 And copy the 100.x.y.z shown. Once you've found it, exit your ssh session, and start a new one with your newly copied Tailscale IP.</p> <p>ssh @ Step 4: Enable UFW <p>For this guide, we'll use UFW (Uncomplicated Firewall) to restrict non-Tailscale traffic to our server. It comes pre-installed on Ubuntu 18.04, so no installation is needed. Before we continue editing rules, you'll need to enable UFW if it isn't already enabled.</p> <p>sudo ufw enable Step 5: Restrict all other traffic</p> <p>Next, we'll set up rules to reject all incoming non-Tailscale traffic, and allow all outgoing traffic by default.</p> <p>sudo ufw default deny incoming sudo ufw default allow outgoing Now that we've set these defaults check your existing firewall rules you might need to keep.</p> <p>sudo ufw status You might see a list of firewall rules, like this:</p> <p>To                          Action      From --                          ------      ---- 22/tcp                      ALLOW IN    Anywhere 80/tcp                      ALLOW IN    Anywhere 443/tcp                     ALLOW IN    Anywhere Anywhere on tailscale0      ALLOW IN    Anywhere 22/tcp (v6)                 ALLOW IN    Anywhere (v6) 80/tcp (v6)                 ALLOW IN    Anywhere (v6) 443/tcp (v6)                ALLOW IN    Anywhere (v6) Anywhere (v6) on tailscale0 ALLOW IN    Anywhere (v6) All other connections are denied by default and so not listed above. We want to limit this list to the minimum set needed. To completely lock down your server while retaining ssh access, you could delete every rule except for the \"Anywhere on tailscale0\" rule. For the example above, we'll delete all \"22/tcp\" rules, which will remove the ability to ssh over regular connections:</p> <p>sudo ufw delete 22/tcp Now, only \"Anywhere on tailscale0\" remains, meaning ssh can only occur over Tailscale.</p> <p>To                          Action      From --                          ------      ---- 80/tcp                      ALLOW       Anywhere 443/tcp                     ALLOW       Anywhere Anywhere on tailscale0      ALLOW IN    Anywhere 80/tcp (v6)                 ALLOW       Anywhere (v6) 443/tcp (v6)                ALLOW       Anywhere (v6) Anywhere (v6) on tailscale0 ALLOW IN    Anywhere (v6) If you expose a public web service (80/tcp, 443/tcp), you'll want to keep those rules around. For less public services like FTP (21/tcp) or a database, consider connecting devices that rely on those services over Tailscale too. This guide assumes ssh is running on the default port, port 22. If you've changed your ssh port, you may need to change these instructions as well. Step 6: Restart ufw and ssh</p> <p>Once you've set up firewall rules to restrict all non-Tailscale connections, restart ufw and ssh</p> <p>sudo ufw reload sudo service ssh restart Done! Now your server will ignore any ssh requests that don't come from users authenticated to your private Tailscale network. Step 7: Test and verify</p> <p>Let's make sure that everything is working as expected. First, let's exit the existing ssh session. Then, let's try to connect with the public IP address from earlier. You should see that we're not able to connect, and the operation times out.</p> <p>ssh @ ssh: connect to host  port 22: Operation timed out Now, let's try to ssh in using the Tailscale IP address (starting with 100.x.y.z) from earlier. <p>ssh @ We're able to connect! Everything is working as expected. exit the ssh connection again. This time, quit the Tailscale client on your local machine. If you try to ssh to the Ubuntu server again, you'll see that the operation now times out and we are no longer able to connect. <p>ssh @ ssh: connect to host  port 22: Operation timed out We've now verified that we can only connect when we're successfully authenticated to the Tailscale client running on our local machine. Optional: enable multi-factor authentication (MFA) for all ssh connections <p>Now that your server can only be accessed via Tailscale, you can enforce login rules in using your Tailscale network's identity provider, knowing they will apply to all your ssh connections too. For example, you may want to configure your identity provider to require multi-factor authentication (MFA) for every sign-in.</p>"},{"location":"linux/ufw/","title":"UFW (uncomplicated firewall)","text":"<p>UFW (uncomplicated firewall) is a firewall configuration tool for Linux ([[linux]]) that runs on top of IPTables ([[iptables]]), included by default within Ubuntu distributions. It provides a streamlined interface for configuring common firewall use cases via the command line.</p>"},{"location":"linux/ufw/#enable-ufw","title":"Enable UFW","text":"<p>To check if ufw is enabled, run: <pre><code>sudo ufw status\n</code></pre></p> <p>To enable UFW on your system, run: <pre><code>sudo ufw enable\n</code></pre></p> <p>If for some reason you need to disable UFW, you can do so with the following command: <pre><code>sudo ufw disable\n</code></pre></p> <p>Block an IP Address</p>"},{"location":"linux/ufw/#block-an-ip-addresssubnet","title":"Block an IP Address/Subnet","text":"<pre><code>sudo ufw deny from 203.0.113.0/24\n</code></pre>"},{"location":"linux/user/","title":"User Management","text":"COMMAND DESCRIPTION <code>sudo adduser username</code> Create a new user <code>sudo userdel username</code> Delete a user <code>sudo usermod -aG groupname username</code> Add a user to group <code>sudo deluser username groupname</code> Remove a user from a group"},{"location":"linux/distros/centos/","title":"CentOS","text":"<p>CentOS, from Community Enterprise Operating System; also known as CentOS Linux) is a Linux distribution that provides a free and open-source community-supported computing platform, functionally compatible with its upstream source, Red Hat Enterprise Linux (RHEL). CentOS announced the official joining with Red Hat while staying independent from RHEL, under a new CentOS governing board.</p>"},{"location":"linux/distros/debian/","title":"Debian","text":"<p>Debian also known as Debian GNU/Linux, is a Linux distribution composed of free and open-source software, developed by the community-supported Debian Project. The Debian Stable branch is the most popular edition for personal computers and servers. Debian is also the basis for many other distributions, most notably Ubuntu.</p>"},{"location":"linux/distros/fedora/","title":"Fedora","text":"<p>Fedora Linux is a Linux distribution developed by the Fedora Project. Fedora contains software distributed under various free and open-source licenses and aims to be on the leading edge of open-source technologies. Fedora is the upstream source for Red Hat Enterprise Linux.</p> <p>Since the release of Fedora 35, six different editions are made available tailored to personal computer, server, cloud computing, container and Internet of Things installations. A new version of Fedora Linux is released every six months.</p> <p>Project Homepage: Home - Fedora Documentation: Fedora Documentation</p>"},{"location":"linux/distros/fedora/#post-install-steps","title":"Post Install Steps","text":""},{"location":"linux/distros/fedora/#1-enable-caching-in-dnf-package-manager","title":"1- Enable Caching in dnf Package Manager","text":"<p>Caching is Enabled to increase dnf speed</p> <p>Edit dnf configuration: <pre><code>sudo nano /etc/dnf/dnf.conf\n</code></pre> Add this lines add the end: <pre><code># Added for speed:\nfastestmirror=True\n#change to 10 if you have fast internet speed\nmax_parallel_downloads=5\n#when click enter the default is yes\ndefaultyes=True\n#Keeps downloaded packages in the cache\nkeepcache=True\n</code></pre> To clean dnf cache periodically: <pre><code>sudo dnf clean dbcache\n#or\nsudo dnf clean all\n</code></pre> for more configuration options: DNF Configuration Reference</p>"},{"location":"linux/distros/fedora/#2-system-update","title":"2- System Update","text":"<p>Run the following command: <pre><code>sudo dnf update\n</code></pre></p>"},{"location":"linux/distros/fedora/#3-enable-rpm-fusion","title":"3- Enable RPM Fusion","text":"<p>RPM Fusion\u00a0provides software that the Fedora Project or Red Hat doesn't want to ship. That software is provided as precompiled RPMs for all current Fedora versions and current Red Hat Enterprise Linux or clones versions; you can use the RPM Fusion repositories with tools like yum and PackageKit.</p> <p>Installing both free and non-free RPM Fusion: <pre><code>sudo dnf install https://mirrors.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm https://mirrors.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm\n</code></pre></p>"},{"location":"linux/distros/fedora/#appstream-metadata","title":"AppStream metadata","text":"<p>to enable users to install packages using Gnome Software/KDE Discover. Please note that these are a subset of all packages since the metadata are only generated for GUI packages.</p> <p>The following command will install the required packages: <pre><code>sudo dnf groupupdate core\n</code></pre></p>"},{"location":"linux/distros/fedora/#4-adding-flatpak","title":"4- Adding Flatpak","text":"<p>Flatpak, formerly known as xdg-app, is a utility for software deployment and package management for Linux. It is advertised as offering a sandbox environment in which users can run application software in isolation from the rest of the system.</p> <p>Flatpak is installed by default on Fedora Workstation, Fedora Silverblue, and Fedora Kinoite. To get started, all you need to do is enable Flathub, which is the best way to get Flatpak apps. Just download and install the\u00a0Flathub repository file</p> <p>The above links should work on the default GNOME and KDE Fedora installations, but if they fail for some reason you can manually add the Flathub remote by running: <pre><code>flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo\n</code></pre></p>"},{"location":"linux/distros/fedora/#5-change-hostname","title":"5- Change Hostname","text":"<p>Run the following command: <pre><code>sudo hostnamectl set-hostname #your-name\n</code></pre></p>"},{"location":"linux/distros/fedora/#6-add-multimedia-codecs","title":"6- Add Multimedia Codecs","text":"<p>Run the following commands: <pre><code>sudo dnf groupupdate multimedia --setop=\"install_weak_deps=False\" --exclude=PackageKit-gstreamer-plugin\n\nsudo dnf groupupdate sound-and-video\n</code></pre></p>"},{"location":"linux/distros/fedora/#7-make-it-more-customizable","title":"7- Make it More  Customizable","text":"<p>Open GNOME software installer and install the following: - GNOME Tweaks - Extensions</p> <p>Consider the following GNOME Extensions: - Vitals - ArcMenu - Custom Hot Corners - Extended - Dash to Panel - Sound input &amp; ouput Device Chooser - OpenWeather - Impatience - Screenshot Tool - Tiling Assistant - Extension List - Clipboard Indicator</p>"},{"location":"linux/distros/ubuntu/","title":"Ubuntu","text":"<p>Ubuntu is a Linux distribution based on Debian and composed mostly of free and open-source software.Ubuntu is officially released in three editions: Desktop, Server, and Core for Internet of things devices and robots. Ubuntu is a popular operating system for cloud computing, with support for OpenStack.</p>"},{"location":"linux/distros/ubuntu/#how-to-enable-sudo-without-a-password-for-a-user","title":"How to enable sudo without a password for a user","text":"<p>Open a Terminal window and type:</p> <pre><code>sudo visudo\n</code></pre> <p>In the bottom of the file, add the following line:</p> <pre><code>$USER ALL=(ALL) NOPASSWD: ALL\n</code></pre> <p>Where <code>$USER</code> is your username on your system. Save and close the sudoers file (if you haven't changed your default terminal editor (you'll know if you have), press Ctl + x to exit <code>nano</code> and it'll prompt you to save).</p>"},{"location":"linux/distros/ubuntu/#networking","title":"Networking","text":"<p>In Ubuntu, networking can be managed using various tools and utilities, including the following:</p> <ol> <li> <p>NetworkManager: NetworkManager is a system service that manages network connections and devices. It provides a graphical user interface (GUI) for configuring network settings, as well as a command-line interface (CLI) for advanced configuration. NetworkManager is the default network management tool in Ubuntu.</p> </li> <li> <p>Netplan: Netplan is a command-line utility for configuring network interfaces in modern versions of Ubuntu. It uses YAML configuration files to describe network interfaces, IP addresses, routes, and other network-related parameters. Netplan generates the corresponding configuration files for the underlying network configuration subsystem, such as systemd-networkd or NetworkManager.</p> </li> <li> <p>ifupdown: ifupdown is a traditional command-line tool for managing network interfaces in Ubuntu. It uses configuration files located in the \ufeff/etc/network/ directory to configure network interfaces, IP addresses, routes, and other network-related parameters.</p> </li> </ol> <p>To manage networking in Ubuntu, you can use one or more of these tools depending on your needs and preferences. For example, you can use the NetworkManager GUI to configure basic network settings and use Netplan or ifupdown for advanced configuration. You can also use the command-line tools to automate network configuration tasks or to configure networking on headless servers.</p>"},{"location":"macos/macos-shortcuts/","title":"MacOS keyboard shortcuts","text":""},{"location":"macos/macos-shortcuts/#table-of-contents","title":"Table of contents","text":"<ul> <li>MacOS keyboard shortcuts</li> <li>Table of contents</li> <li>Mac Keyboard Modifier keys</li> <li>Cut, copy, paste, and other common shortcuts</li> <li>Sleep, log out, and shut down shortcuts</li> <li>Finder and system shortcuts</li> <li>Document shortcuts</li> </ul>"},{"location":"macos/macos-shortcuts/#mac-keyboard-modifier-keys","title":"Mac Keyboard Modifier keys","text":"key description \u2318 \u2318 +  / Cmd \u2303 Control / Ctrl \u2325 \u2325 + s / Alt \u21e7 Shift \u21ea Caps Lock Fn Function key <p>- On Windows keyboards use the Alt key instead of \u2325 + , and the Windows logo key instead of \u2318 + .</p>"},{"location":"macos/macos-shortcuts/#cut-copy-paste-and-other-common-shortcuts","title":"Cut, copy, paste, and other common shortcuts","text":"keys description \u2318 + x Cut the selected item and copy it to the Clipboard \u2318 + c Copy the selected item to the Clipboard. This also works for files in the Finder \u2318 + v Paste the contents of the Clipboard into the current document or app. This also works for files in the Finder \u2318 + z Undo the previous comamnd \u21e7 + \u2318 + z Redo, reversing the undo command \u2318 + a Select All items \u2318 + f Find items in a document or open a Find window \u2318 + g Find Again: Find the next occurrence of the item previously found \u21e7 + \u2318 + G Find the previous occurrence \u2318 + h Hide the windows of the front app \u2325 + \u2318 + h View the front app but hide all other apps \u2318 + m Minimize the front window to the Dock \u2325 + \u2318 + m Minimize all windows of the front app \u2318 + o Open the selected item, or open a dialog to select a file to open \u2318 + p Print the current document \u2318 + s Save the current document \u2318 + t Open a new tab \u2318 + w Close the front window \u2325 + \u2318 + w Close all windows of the app \u2325 + \u2318 + Esc Force quit an app \u2318 + Space Show or hide the Spotlight search field \u2318 + \u2325 + Space Perform a Spotlight search from a Finder window \u2303 + \u2318 + Space Show the Character Viewer, from which you can choose emoji and other symbols \u2303 + \u2318 + f Use the app in full screen, if supported by the app Space Use Quick Look to preview the selected item \u2318 + Tab Switch to the next most recently used app among your open apps \u21e7 + \u2318 + 5 In macOS Mojave or later, take a screenshot or make a screen recording \u21e7 + \u2318 + 3 Take whole display screenshot \u21e7 + \u2318 + 4 Take custom screenshot \u21e7 + \u2318 + n Create a new folder in the Finder \u2318 + , Open preferences for the front app"},{"location":"macos/macos-shortcuts/#sleep-log-out-and-shut-down-shortcuts","title":"Sleep, log out, and shut down shortcuts","text":"<p>* You might need to press and hold some of these shortcuts for slightly longer than other shortcuts. This helps you to avoid using them unintentionally.</p> keys description Power button Press to turn on your Mac or wake it from sleep Power button Press and hold for 1.5 seconds to put your Mac to sleep Power button Press and continue holding to force your Mac to turn off \u2325 + \u2318 + Power Put your Mac to sleep \u2325 + \u2318 + Eject Put your Mac to sleep \u2303 + \u21e7 + Power Put your displays to sleep \u2303 + \u21e7 + Eject Put your displays to sleep \u2303 + Power Display a dialog asking whether you want to restart, sleep, or shut down \u2303 + Eject Display a dialog asking whether you want to restart, sleep, or shut down \u2303 + \u2318 + Power Force your Mac to restart, without prompting to save any open and unsaved documents \u2303 + \u2318 + Eject Quit all apps, then restart your Mac \u2303 + \u2325 + \u2318 + Power Quit all apps, then shut down your Mac \u2303 \u2325 + \u2318 + Eject Quit all apps, then shut down your Mac \u2303 + \u2318 + q Immediately lock your screen \u21e7 + \u2318 + q Log out of your macOS user account. You will be asked to confirm \u2325 + \u21e7 + \u2318 + q Log out immediately without confirming"},{"location":"macos/macos-shortcuts/#finder-and-system-shortcuts","title":"Finder and system shortcuts","text":"keys description \u2318 + d Duplicate the selected files \u2318 + e Eject the selected disk or volume \u2318 + f Start a Spotlight search in the Finder window \u2318 + i Show the Get Info window for a selected file \u2318 + r (1) When an alias is selected in the Finder: show the original file for the selected alias \u2318 + r (2) In some apps, such as Calendar or Safari, refresh or reload the page \u2318 + r (3) In Software Update preferences, check for software updates again \u21e7 + \u2318 + c Open the Computer window \u21e7 + \u2318 + d Open the desktop folder \u21e7 + \u2318 + f Open the Recents window, showing all of the files you viewed or changed recently \u21e7 + \u2318 + g Open a Go to Folder window \u21e7 + \u2318 + h Open the Home folder of the current macOS user account \u21e7 + \u2318 + i Open iCloud Drive \u21e7 + \u2318 + k Open the Network window \u2325 + \u2318 + l Open the Downloads folder \u21e7 + \u2318 + n Create a new folder \u21e7 + \u2318 + o Open the Documents folder \u21e7 + \u2318 + p Show or hide the Preview pane in Finder windows \u21e7 + \u2318 + r Open the AirDrop window \u21e7 + \u2318 + t Show or hide the tab bar in Finder windows \u2303 + \u21e7 + \u2318 + t Add selected Finder item to the Dock (OS X Mavericks or later) \u21e7 + \u2318 + u Open the Utilities folder \u2325 + \u2318 + d Show or hide the Dock \u2303 + \u2318 + t Add the selected item to the sidebar (OS X Mavericks or later) \u2325 + \u2318 + p Hide or show the path bar in Finder windows \u2325 + \u2318 + s Hide or show the Sidebar in Finder windows \u2318 + / Hide or show the status bar in Finder windows \u2318 + j Show View Options \u2318 + k Open the Connect to Server window \u2303 + \u2318 + a Make an alias of the selected item \u2318 + n Open a new Finder window \u2325 + \u2318 + n Create a new Smart Folder \u2318 + t Show or hide the tab bar when a single tab is open in the current Finder window \u2325 + \u2318 + t Show or hide the toolbar when a single tab is open in the current Finder window \u2325 + \u2318 + v Move the files in the Clipboard from their original location to the current location \u2318 + y Use Quick Look to preview the selected files \u2325 + \u2318 + v View a Quick Look slideshow of the selected files \u2318 + 1 View the items in the Finder window as icons \u2318 + 2 View the items in a Finder window as a list \u2318 + 3 View the items in a Finder window in columns \u2318 + 4 View the items in a Finder window in a gallery \u2318 + [ Go to the previous folder \u2318 + ] Go to the next folder \u2318 + \u2191 Open the folder that contains the current folder \u2303 + \u2318 + \u2191 Open the folder that contains the current folder in a new window \u2318 + \u2193 Open the selected item \u2192 Open the selected folder. This works only when in list view \u2190 Close the selected folder. This works only when in list view \u2318 + Delete Move the selected item to the Trash \u21e7 + \u2318 + Delete Empty the Trash \u2325 + \u21e7 + \u2318 + Delete Empty the Trash without confirmation dialog \u2318 + Brightness Down Turn video mirroring on or off when your Mac is connected to more than one display \u2325 + Brightness Up Open Displays preferences. This works with either Brightness key \u2303 + Brightness Up/Down Adjust brightness of your external display, if supported by your display \u2325 + \u21e7 + Brightness Up/Down Adjust display brightness in smaller steps \u2303 + \u2325 + \u21e7 + Brightness Up/Down Adjust external display brightness in smaller steps, if supported by display \u2325 + Mission Control Open Mission Control preferences \u2303 + Mission Control Show the desktop \u2303 + \u2193 Show all windows of the front app \u2325 + Volume Up Open Sound preferences. This works with any of the volume keys \u2325 + \u21e7 + Volume up/Down Adjust the sound volume in smaller steps \u2325 + Brightness Up Open Keyboard preferences. This works with either Keyboard Brightness key \u2325 + \u21e7 + Brightness Up/Down Adjust the keyboard brightness in smaller steps \u2325 + double-clicking Open the item in a separate window, then close the original window \u2318 + double-clicking Open a folder in a separate tab or window \u2318 + dragging to another volume Move the dragged item to the other volume, instead of copying it \u2325 + dragging Copy the dragged item. The pointer changes while you drag the item \u2325 + \u2318 + while dragging Make an alias of the dragged item. The pointer changes while you drag the item \u2325 + click a disclosure triangle Open all folders within the selected folder. This works only when in list view \u2318 + click a window title See the folders that contain the current folder"},{"location":"macos/macos-shortcuts/#document-shortcuts","title":"Document shortcuts","text":"<p>*The behavior of these shortcuts may vary with the app you're using</p> keys description \u2318 + b Boldface the selected text, or turn boldfacing on or off \u2318 + i Italicize the selected text, or turn italics on or off \u2318 + k Add a web link \u2318 + u Underline the selected text, or turn underlining on or off \u2318 + t Show or hide the Fonts window \u2318 + d Select the Desktop folder from within an Open dialog or Save dialog \u2303 + \u2318 + d Show or hide the definition of the selected word \u21e7 + \u2318 + : Display the Spelling and Grammar window \u2318 + ; Find misspelled words in the document \u2325 + Delete Delete the word to the left of the insertion point \u2303 + h Delete the character to the left of the insertion point. Or use Delete \u2303 + d Delete the character to the right of the insertion point Fn + Delete Forward delete on keyboards that don't have a Forward Delete key \u2303 + k Delete the text between the insertion point and the end of the line or paragraph Fn + \u2191 Page Up: Scroll up one page Fn + \u2193 Page Down: Scroll down one page. Fn + \u2190 Home: Scroll to the beginning of a document. Fn + \u2192 End: Scroll to the end of a document. \u2318 + \u2191 Move the insertion point to the beginning of the document \u2318 + \u2193 Move the insertion point to the end of the document. \u2318 + \u2190 Move the insertion point to the beginning of the current line. \u2318 + \u2192 Move the insertion point to the end of the current line. \u2325 + \u2190 Move the insertion point to the beginning of the previous word \u2325 + \u2192 Move the insertion point to the end of the next word \u21e7 + \u2318 + \u2191 Select the text between the insertion point and the beginning of the document \u21e7 + \u2318 + \u2193 Select the text between the insertion point and the end of the document \u21e7 + \u2318 + \u2190 Select the text between the insertion point and the beginning of the current line \u21e7 + \u2318 + \u2192 Select the text between the insertion point and the end of the current line \u21e7 + \u2191 Extend text selection to the nearest character at the same horizontal location on the line above \u21e7 + \u2193 Extend text selection to the nearest character at the same horizontal location on the line below \u21e7 + \u2190 Extend text selection one character to the left \u21e7 + \u2192 Extend text selection one character to the right \u2325 + \u21e7 + \u2191 Extend text selection to the beginning of the current paragraph, then to the beginning of the following paragraph if pressed again \u2325 + \u21e7 + \u2193 Extend text selection to the end of the current paragraph, then to the end of the following paragraph if pressed again \u2325 + \u21e7 + \u2190 Extend text selection to the beginning of the current word, then to the beginning of the following word if pressed again \u2325 + \u21e7 + \u2192 Extend text selection to the end of the current word, then to the end of the following word if pressed again \u2303 + a Move to the beginning of the line or paragraph \u2303 + e Move to the end of a line or paragraph \u2303 + f Move one character forward \u2303 + b Move one character backward \u2303 + l Center the cursor or selection in the visible area \u2303 + p Move up one line \u2303 + n Move down one line \u2303 + o Insert a new line after the insertion point \u2303 + t Swap the character behind the insertion point with the character in front of the insertion point \u2318 + { Left align \u2318 + } Right align \u21e7 + \u2318 + | Center align \u2325 + \u2318 + f Go to the search field \u2325 + \u2318 + t Show or hide a toolbar in the app \u2325 + \u2318 + c Copy Style: Copy the formatting settings of the selected item to the Clipboard \u2325 + \u2318 + v Paste Style: Apply the copied style to the selected item \u2325 + \u21e7 + \u2318 + v Paste and Match Style: Apply the style of the surrounding content to the item pasted within that content \u2325 + \u2318 + i Show or hide the inspector window \u21e7 + \u2318 + p Page setup: Display a window for selecting document settings \u21e7 + \u2318 + s Display the Save As dialog, or duplicate the current document \u21e7 + \u2318 + (-) Decrease the size of the selected item \u21e7 + \u2318 + (+) Increase the size of the selected item \u2318 + = performs the same function \u21e7 + \u2318 + ? Open the Help menu"},{"location":"macos/setup_terminal/","title":"MacOS Terminal aufsetzen und mit Oh-MyZsh konfigurieren","text":""},{"location":"macos/setup_terminal/#homebrew-installieren","title":"Homebrew installieren","text":"<p>Terminal \u00f6ffnen und folgenden Command ausf\u00fchren <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre></p>"},{"location":"macos/setup_terminal/#homebrew-zum-fahd-hinzufugen","title":"Homebrew zum Fahd hinzuf\u00fcgen","text":"<p>Nach der Installation, ACHTUNG: \u201d[username]\u201d mit dem aktuellen Usernamen ersetzen <pre><code>echo 'eval \"$(/opt/homebrew/bin/brew shellenv)\"' &gt;&gt; /Users/[username]/.zprofile\neval \"$(/opt/homebrew/bin/brew shellenv)\"\n</code></pre></p>"},{"location":"macos/setup_terminal/#iterm2-installieren","title":"iTerm2 installieren","text":"<p>F\u00fcr die Installation: <pre><code>brew install --cask iterm2\n</code></pre></p>"},{"location":"macos/setup_terminal/#git-installieren","title":"Git installieren","text":"<p>F\u00fcr die Installaation: <pre><code>brew install git\n</code></pre></p>"},{"location":"macos/setup_terminal/#oh-my-zsh-installieren","title":"Oh My Zsh installieren","text":"<p>Im Terminal folgende Befehl ausf\u00fchren: <pre><code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n</code></pre></p>"},{"location":"macos/setup_terminal/#istallation-powerlevel10k-theme-fur-oh-my-zsh","title":"Istallation PowerLevel10K Theme f\u00fcr Oh My Zsh","text":"<p>Theme herunterladen</p> <pre><code>git clone https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k\n</code></pre> <p>Nach dem Download das File \u201d~/.zshrc\u201d \u00f6ffnen. und den Wert von \u201cZSH_THEME\" ab\u00e4ndern wie unten gezeigt: <pre><code>ZSH_THEME=\"powerlevel10k/powerlevel10k\"\n</code></pre> Dann die Datei speichern und Terminal neu starten oder den folgenden Command ausf\u00fchren:</p> <pre><code>source ~/.zshrc\n</code></pre>"},{"location":"macos/setup_terminal/#meslo-nerd-font-installieren","title":"Meslo Nerd Font installieren","text":"<p>Font installieren mit \"y\" best\u00e4tigen und iTerm2 schliessen.</p>"},{"location":"macos/setup_terminal/#update-vscode-terminalfont-optional","title":"Update VSCode TerminalFont (Optional)","text":"<p>Einstellungen \u00f6ffnen und in Terminal FontFamili den Wert \"MesloLGS NF\" eintragen oder im settings.json den folgenden Wert hinzuf\u00fcgen:</p> <pre><code>\"terminal.integrated.fontFamily\": \"MesloLGS NF\"\n</code></pre>"},{"location":"macos/setup_terminal/#configure-powerlevel10k","title":"Configure PowerLevel10K","text":"<p>iTerm2 restarten. Man sollte jetzt den PowerLevel10K Configurations-Prozess sehen. Wenn nicht, den Proezss mit dem folgenden Command starten:</p> <pre><code>p10k configure\n</code></pre> <p>Mit den foglenden Einstellungen kann das Terminal angepasst werden.</p>"},{"location":"macos/setup_terminal/#schritgrosse","title":"Schritgr\u00f6sse","text":"<ol> <li>Einstellungen von iTerm2 \u00f6ffnen</li> <li>Auf Profiles -&gt; Text</li> <li>Schriftgr\u00f6sse auf ca. 20 stellen</li> </ol>"},{"location":"macos/setup_terminal/#wechel-der-farbgebung","title":"Wechel der Farbgebung","text":"<ol> <li>iTerm2 \u00f6ffnen</li> <li>Download den Theme  <pre><code>curl https://raw.githubusercontent.com/josean-dev/dev-environment-files/main/coolnight.itermcolors --output ~/Downloads/coolnight.itermcolors\n</code></pre></li> <li>Einstellungen von iTerm2 \u00f6ffnen</li> <li>Auf Profile -&gt; Colors githubusercontent</li> <li>Den heruntergeladenen Theme importieren (coolnight)</li> <li>Das Profil ausw\u00e4hlen (collnight)</li> </ol>"},{"location":"macos/setup_terminal/#zsh-plugins-installieren","title":"ZSH Plugins installieren","text":"<p>Install zsh-augosuggestions: <pre><code>git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n</code></pre></p> <p>Install zsh-syntax-highlighting: <pre><code>git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n</code></pre></p> <p>\u00d6ffnen von \u201d~/.zshrc\u201d und die Plugins hinzuf\u00fcgen. Die Zeile sollte dann so aussehen: <pre><code>plugins=(git zsh-autosuggestions zsh-syntax-highlighting web-search)\n</code></pre></p> <p>Die Plugins Laden mit dem Command: <pre><code>source ~/.zshrc\n</code></pre></p>"},{"location":"macos/setup_terminal/#fertig","title":"Fertig!","text":"<p>Quelle: https://www.josean.com/posts/terminal-setup</p>"},{"location":"macos/sshkey-gen/","title":"SSH Key erstellen und auf einen Server kopieren","text":"<ol> <li>SSH-Schl\u00fcssel erstellen \u00d6ffnen Sie das Terminal auf Ihrem macOS-System und geben Sie den folgenden Befehl ein, um einen neuen SSH-Schl\u00fcssel zu erstellen. Es wird empfohlen, einen RSA-Schl\u00fcssel mit einer L\u00e4nge von 4096 Bits zu verwenden, um eine gute Sicherheit zu gew\u00e4hrleisten:</li> </ol> <pre><code>ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n</code></pre> <p>Ersetzen Sie your_email@example.com mit Ihrer E-Mail-Adresse. Dieser Schritt wird dazu verwendet, Ihren \u00f6ffentlichen Schl\u00fcssel zu identifizieren, ist aber nicht zwingend erforderlich.</p> <p>Sie werden aufgefordert, den Speicherort f\u00fcr den Schl\u00fcssel zu w\u00e4hlen (normalerweise ~/.ssh/id_rsa) und ein Passwort einzugeben, um den Schl\u00fcssel zu sch\u00fctzen.</p> <ol> <li>SSH-Schl\u00fcssel auf Ubuntu kopieren Nachdem Sie den SSH-Schl\u00fcssel erstellt haben, k\u00f6nnen Sie ihn auf Ihre Ubuntu-Maschine kopieren. Dieser Vorgang wird \u00fcblicherweise mit dem Befehl ssh-copy-id durchgef\u00fchrt. F\u00fchren Sie im Terminal auf Ihrem macOS-System den folgenden Befehl aus: <pre><code>ssh-copy-id -i ~/.ssh/id_rsa.pub username@ubuntu-server\n</code></pre></li> </ol> <p>Ersetzen Sie username mit dem Benutzernamen auf der Ubuntu-Maschine und ubuntu-server mit der IP-Adresse oder dem Hostnamen des Ubuntu-Servers. Dieser Befehl \u00fcbertr\u00e4gt Ihren \u00f6ffentlichen SSH-Schl\u00fcssel auf den Ubuntu-Server und f\u00fcgt ihn zur Datei ~/.ssh/authorized_keys des entsprechenden Benutzers hinzu, wodurch Sie sich zuk\u00fcnftig ohne Passworteingabe anmelden k\u00f6nnen.</p> <ol> <li>Test der SSH-Verbindung Nachdem Sie den Schl\u00fcssel kopiert haben, k\u00f6nnen Sie testen, ob Sie sich ohne Passwort \u00fcber SSH verbinden k\u00f6nnen. Verwenden Sie dazu den folgenden Befehl:</li> </ol> <p><pre><code>ssh username@ubuntu-server\n</code></pre> Wenn alles richtig eingerichtet wurde, sollten Sie ohne Passworteingabe auf den Ubuntu-Server zugreifen k\u00f6nnen.</p>"},{"location":"macos/sshkey-gen/#sicherheitshinweise","title":"Sicherheitshinweise","text":"<ul> <li>Schl\u00fcssel mit Passwort sch\u00fctzen: W\u00e4hlen Sie ein starkes Passwort f\u00fcr Ihren privaten Schl\u00fcssel.</li> <li>Regelm\u00e4\u00dfige \u00dcberpr\u00fcfung: \u00dcberpr\u00fcfen Sie regelm\u00e4\u00dfig die Datei ~/.ssh/authorized_keys auf Ihren Servern, um sicherzustellen, dass keine unbefugten Schl\u00fcssel vorhanden sind.</li> <li>Einschr\u00e4nkung der SSH-Zugriffsrechte: \u00dcberlegen Sie, ob Sie in der SSH-Konfigurationsdatei (/etc/ssh/sshd_config) Einstellungen wie AllowUsers oder AllowGroups verwenden, um den Zugriff weiter zu beschr\u00e4nken.</li> </ul>"},{"location":"macos/vscode-macos-shortcuts/","title":"VSCode shortcuts","text":"<ul> <li>MacOS vscode keyboard shortcuts</li> <li>Howto vscode custom shortcuts</li> <li>Learn vscode keyboard shortcuts</li> </ul>"},{"location":"macos/vscode-macos-shortcuts/#side-menu","title":"Side Menu","text":"shortcut description \u2318 + B Hide show side menu \u2318 + \u21e7 + E Explorer window \u2318 + \u21e7 + F Find window \u2318 + \u21e7 + J Find in files window \u2303 + \u21e7 + G Git window \u2318 + \u21e7 + D Debug window \u2318 + \u21e7 + X Extension window"},{"location":"macos/vscode-macos-shortcuts/#multi-cursor-editing","title":"Multi-Cursor Editing","text":"shortcut description \u2318 + \u2325 + \u2193 add a new cursor below \u2325 + Click add a new cursor at the mouse click \u2318 + \u21e7 + L add new cursor behind all instances of a word"},{"location":"macos/vscode-macos-shortcuts/#split-editor","title":"Split editor","text":"shortcut description \u2318 + \\ split"},{"location":"macos/vscode-macos-shortcuts/#split-window-focusing","title":"Split Window focusing","text":"shortcut description \u2318 + 0 explorer panel \u2318 + 1 1st window split window \u2318 + 2 2nd window split window \u2303 + ~ terminal window ^ + tab switch between tabs \u2318 + ~ switch between VS code editor windows"},{"location":"macos/vscode-macos-shortcuts/#intellisense","title":"IntelliSense","text":"shortcut description \u2303 + Space to invoke IntelliSense"},{"location":"macos/vscode-macos-shortcuts/#line-action","title":"Line Action","text":"shortcut description \u21e7 + \u2325 + \u2193 copy the line and insert below \u21e7 + \u2325 + \u2191 copy the line and insert above \u2325 + \u2193 move entire line below \u2325 + \u2191 move entire line above \u2318 + \u21e7 + K delete entire line"},{"location":"macos/vscode-macos-shortcuts/#rename-refactoring","title":"Rename Refactoring","text":"shortcut description F2 (Fn + F2) Rename Symbol in the current project Right Mouse Click -&gt; Rename Symbol Rename Symbol in the current project"},{"location":"macos/vscode-macos-shortcuts/#formatting","title":"Formatting","text":"shortcut description \u21e7 + \u2325 + F format entire document \u2318 + K and \u2318 F format selected text"},{"location":"macos/vscode-macos-shortcuts/#transform-selected","title":"Transform selected","text":"shortcut description ^ + \u21e7 + \u2325 + L transform selected to lower ^ + \u21e7 + \u2325 + U transform selected to upper ^ + \u21e7 + \u2325 + S transform selected to snake ^ + \u21e7 + \u2325 + T transform selected to titelcase"},{"location":"macos/vscode-macos-shortcuts/#code-folding","title":"Code Folding","text":"shortcut description \u2318 + \u2325 + [ fold \u2318 + \u2325 + ] unfold \u2318 K and \u2318 0 fold all \u2318 K and \u2318 J unfold all \u2318 K and \u2318 1 fold 1 level \u2318 K and \u2318 2 fold 2 levels \u2318 K and \u2318 5 fold 5 levels"},{"location":"macos/vscode-macos-shortcuts/#errors-and-warnings","title":"Errors and Warnings","text":"shortcut description F8 navigate across errors"}]}